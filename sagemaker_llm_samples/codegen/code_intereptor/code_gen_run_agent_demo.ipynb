{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08da17e4-482f-462b-97af-ca91f0ea654a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.0.335)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (0.6.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (0.0.64)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.1.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "#!pip install gradio==4.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec97961-461e-4ff2-a2a9-67032c42c928",
   "metadata": {},
   "source": [
    "## initial bedrock client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48179687-b1d3-4073-bbd5-f99c1947e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "import boto3\n",
    "import json\n",
    "from botocore.config import Config\n",
    "from botocore.config import Config\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.agents import Tool, AgentExecutor, AgentOutputParser\n",
    "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import BaseRetriever\n",
    "from langchain.callbacks.manager import CallbackManagerForRetrieverRun\n",
    "from langchain.schema import BaseRetriever, Document\n",
    "from typing import Any, Dict, List, Optional,Union\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\n",
    "from langchain.schema.messages import SystemMessage\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "import re\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "import io\n",
    "\n",
    "output = io.BytesIO()\n",
    "\n",
    "\n",
    "def get_bedrock_client(\n",
    "    assumed_role: Optional[str] = None,\n",
    "    region: Optional[str] = None,\n",
    "    runtime: Optional[bool] = True,\n",
    "):\n",
    "  \n",
    "    if region is None:\n",
    "        target_region = os.environ.get(\"AWS_REGION\", os.environ.get(\"AWS_DEFAULT_REGION\"))\n",
    "    else:\n",
    "        target_region = region\n",
    "\n",
    "    print(f\"Create new client\\n  Using region: {target_region}\")\n",
    "    session_kwargs = {\"region_name\": target_region}\n",
    "    client_kwargs = {**session_kwargs}\n",
    "\n",
    "    profile_name = os.environ.get(\"AWS_PROFILE\")\n",
    "    if profile_name:\n",
    "        print(f\"  Using profile: {profile_name}\")\n",
    "        session_kwargs[\"profile_name\"] = profile_name\n",
    "\n",
    "    retry_config = Config(\n",
    "        region_name=target_region,\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "    session = boto3.Session(**session_kwargs)\n",
    "\n",
    "    if assumed_role:\n",
    "        print(f\"  Using role: {assumed_role}\", end='')\n",
    "        sts = session.client(\"sts\")\n",
    "        response = sts.assume_role(\n",
    "            RoleArn=str(assumed_role),\n",
    "            RoleSessionName=\"langchain-llm-1\"\n",
    "        )\n",
    "        print(\" ... successful!\")\n",
    "        client_kwargs[\"aws_access_key_id\"] = response[\"Credentials\"][\"AccessKeyId\"]\n",
    "        client_kwargs[\"aws_secret_access_key\"] = response[\"Credentials\"][\"SecretAccessKey\"]\n",
    "        client_kwargs[\"aws_session_token\"] = response[\"Credentials\"][\"SessionToken\"]\n",
    "        \n",
    "\n",
    "    if runtime:\n",
    "        service_name='bedrock-runtime'\n",
    "    else:\n",
    "        service_name='bedrock'\n",
    "\n",
    "    client_kwargs[\"aws_access_key_id\"] = os.environ.get(\"AWS_ACCESS_KEY_ID\",\"\")\n",
    "    client_kwargs[\"aws_secret_access_key\"] = os.environ.get(\"AWS_SECRET_ACCESS_KEY\",\"\")\n",
    "    \n",
    "    bedrock_client = session.client(\n",
    "        service_name=service_name,\n",
    "        config=retry_config,\n",
    "        **client_kwargs\n",
    "    )\n",
    "\n",
    "    print(\"boto3 Bedrock client successfully created!\")\n",
    "    print(bedrock_client._endpoint)\n",
    "    return bedrock_client\n",
    "\n",
    "\n",
    "\n",
    "## for aksk bedrock\n",
    "def get_bedrock_aksk(secret_name='chatbot_bedrock', region_name = \"us-west-2\"):\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        # For a list of exceptions thrown, see\n",
    "        # https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "        raise e\n",
    "\n",
    "    # Decrypts secret using the associated KMS key.\n",
    "    secret = json.loads(get_secret_value_response['SecretString'])\n",
    "    return secret['BEDROCK_ACCESS_KEY'],secret['BEDROCK_SECRET_KEY']\n",
    "\n",
    "ACCESS_KEY, SECRET_KEY=get_bedrock_aksk()\n",
    "\n",
    "#role based initial client#######\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\"  # E.g. \"us-east-1\"\n",
    "os.environ[\"AWS_PROFILE\"] = \"default\"\n",
    "#os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"arn:aws:iam::687912291502:role/service-role/AmazonSageMaker-ExecutionRole-20211013T113123\"  # E.g. \"arn:aws:...\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]=ACCESS_KEY\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]=SECRET_KEY\n",
    "\n",
    "\n",
    "#新boto3 sdk只能session方式初始化bedrock\n",
    "boto3_bedrock = get_bedrock_client(\n",
    "    #assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")\n",
    "\n",
    "parameters_bedrock = {\n",
    "    \"max_tokens_to_sample\": 2048,\n",
    "    #\"temperature\": 0.5,\n",
    "    \"temperature\": 0.3,\n",
    "    #\"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "}\n",
    "\n",
    "\n",
    "def log(msg):\n",
    "    output.write(msg.encode('utf-8'))\n",
    "    print(output.getvalue().decode('utf-8'))\n",
    "    #output.write(b'\\n')\n",
    "    #output.seek(0, 2) #定位到末尾,以便下次写入\n",
    "\n",
    "class StreamingCustomerizedCallbackHandler(BaseCallbackHandler): \n",
    "    global output\n",
    "    def on_llm_new_token(self, token: str, **kwargs: Any) -> None:\n",
    "        #sys.stdout.write(token)\n",
    "        #sys.stdout.flush()\n",
    "        log(token)\n",
    "        \n",
    "    def on_chain_start(\n",
    "        self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs: Any\n",
    "    ) -> Any:\n",
    "        output.truncate(0)\n",
    "        print(output.getvalue().decode('utf-8'))\n",
    "\n",
    "\n",
    "bedrock_llm = Bedrock(model_id=\"anthropic.claude-v2\", client=boto3_bedrock, \n",
    "                      model_kwargs=parameters_bedrock,streaming=True,\n",
    "                      callbacks=[StreamingCustomerizedCallbackHandler()],)\n",
    "###test the bedrock langchain integration###\n",
    "#response=bedrock_llm.predict(\"镇江关是哪里？\")\n",
    "#response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "47f717da-3846-4497-984b-c074aac0492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\n",
    "from langchain.schema.messages import SystemMessage\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "cot_template = \"\"\"\n",
    "        You are an experienced AWS CLI expert who can effectively troubleshoot and resolve issues.\n",
    "        Generate AWS CLI scripts to troubleshoot user's questions\n",
    "        Ensure the script is clear, concise, and includes specific details about the expected user's question . Specify the length and format for any troubleshooting documentation that needs to be provided.\n",
    "        ### Note: Please only respond if you have extensive experience with the AWS CLI and can confidently troubleshoot and resolve issues.\n",
    "        user's question is in the following <question> tags:\n",
    "        <question>\n",
    "        {input}\n",
    "        </question>\n",
    "        \n",
    "        please write the generated scripts into following <result> tags:\n",
    "        <result>\n",
    "        </result>\n",
    "        \"\"\"\n",
    "\n",
    "awscli_template = \"\"\"\n",
    "        The following is a friendly conversation between a human and an AI. The AI will respond with plain string based on the AWS CLI script output \n",
    "        please write the generated scripts into following <result> tags:\n",
    "        <result>\n",
    "        </result>\n",
    "        \n",
    "        Here is my question:\n",
    "          {input}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"], template=cot_template\n",
    ")\n",
    "bedrock_chain = LLMChain(llm=bedrock_llm, prompt=prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8898e4c4-0035-4ac9-b759-55c538a49512",
   "metadata": {
    "tags": []
   },
   "source": [
    "### chain test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c766c0-4e84-4377-a58c-880fc257d000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "gen_response=bedrock_chain.run(\"安全组放开了22端口的aws EC2实例有哪些?\")\n",
    "print(gen_response)\n",
    "pattern = re.compile(r'<result>(.*?)</result>', re.DOTALL)\n",
    "results = re.findall(pattern, gen_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b718e7a-8916-498b-9e27-466e9e479396",
   "metadata": {
    "tags": []
   },
   "source": [
    "### agent test ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "97db14b5-84be-4d4a-9f3d-77c120fa8a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "query=\"\"\n",
    "output.truncate(0)\n",
    "def execution_request(code:str):\n",
    "    global query\n",
    "    code = query\n",
    "    data = {\n",
    "        \"language\": \"bash\", \n",
    "        \"version\":\"5.2.0\",\n",
    "        \"files\":[{\"name\": \"awscli-gen.sh\",\"content\": code}],\n",
    "        \"stdin\": \"\", \n",
    "        \"args\": [], \n",
    "        \"compile_timeout\": 10000, \n",
    "        \"run_timeout\": 3000, \n",
    "        \"compile_memory_limit\": -1, \n",
    "        \"run_memory_limit\": -1\n",
    "    }\n",
    "    response = requests.post(\"http://code.yanjun.xyz/api/v2/execute\", verify=False, json=data)\n",
    "    #response = requests.post(\"http://172.31.25.136:2000/api/v2/execute\", verify=False, json=data)\n",
    "    result = response.json()\n",
    "    return result\n",
    "\n",
    "\n",
    "def awscli_code_gen(user_query:str):\n",
    "    global query\n",
    "    gen_response=bedrock_chain.run(user_query)\n",
    "    #print(\"orginal code output==\"+gen_response)\n",
    "    #pattern = re.compile(r'`{3}bash\\n(.*?)\\n`{3}', re.DOTALL)\n",
    "    pattern = re.compile(r'<result>(.*?)</result>', re.DOTALL)\n",
    "    results = re.findall(pattern, gen_response)\n",
    "    #print(type(results[0]))\n",
    "    #print(results[0])\n",
    "    #for test only\n",
    "    prefix=\"\"\" \n",
    "    export AWS_DEFAULT_REGION=us-west-2\n",
    "    export AWS_ACCESS_KEY_ID=********\n",
    "    export AWS_SECRET_ACCESS_KEY=********\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    query = results[0]\n",
    "    return query\n",
    "\n",
    "runtime_tool = Tool(\n",
    "    name=\"run the code with AWS runtime\",\n",
    "    func=execution_request,\n",
    "    description=\"useful for when you need to run the code with AWS runtime to get final result\",\n",
    ")\n",
    "codegen_tool = Tool(\n",
    "    func=awscli_code_gen,\n",
    "    name=\"AWS CLI script code generation\",\n",
    "    description=\"useful for when you need to generate aws cli scripte code\",\n",
    ")\n",
    "custom_tool_list = [runtime_tool,codegen_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647c97ed-9d00-4318-8188-3b49e19c3c1b",
   "metadata": {},
   "source": [
    "* for func test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f01bb8fd-5cb3-4cbd-a4df-e01849699268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#code=\"\"\"\n",
    "#export AWS_DEFAULT_REGION=us-west-2\n",
    "#export AWS_ACCESS_KEY_ID=*********\n",
    "#export AWS_SECRET_ACCESS_KEY=**********\n",
    "#aws ec2 describe-instances --query 'Reservations[*].Instances[*].[InstanceId,SecurityGroups[].GroupId]' --output text | awk '{print $1, $2}' | while read InstanceId SGId; do\n",
    "#  aws ec2 describe-security-groups --group-ids $SGId --query 'SecurityGroups[*].IpPermissions[*].[FromPort,ToPort,IpProtocol]' --output text | grep -q '^80\\s*80\\s*tcp$' && echo $InstanceId;\n",
    "#done\n",
    "#\"\"\"\n",
    "#execution_request(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "766bba4a-3b72-4c44-9d88-6ef0f9978a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerized_instructions=\"\"\"\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "These are guidance on when to use a tool to solve a task, follow them strictly:\n",
    " - first use \"AWS CLI script code generation\" tool to generate aws script\n",
    " - then use \"run code with AWS runtime\" tool to execute the generated scripts and return result\n",
    "\"\"\"\n",
    "\n",
    "##use customerized outputparse to fix claude not match \n",
    "##langchain's openai ReAct template don't have \n",
    "##final answer issue \n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        #print(\"cur step's llm_output ===\"+llm_output)\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output},\n",
    "                log=llm_output,\n",
    "            )\n",
    "            #raise OutputParserException(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ed09f7-830c-413f-9ed9-6da2be537bc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()\n",
    "memory = ConversationBufferWindowMemory(k=2,memory_key=\"chat_history\", input_key='input', output_key=\"output\")\n",
    "agent_executor = initialize_agent(custom_tool_list, bedrock_llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, \n",
    "                                  verbose=True,max_iterations=3,\n",
    "                                  return_intermediate_steps=True,\n",
    "                                  handle_parsing_errors=True,\n",
    "                                  memory=memory,\n",
    "                                  agent_kwargs={\n",
    "                                      \"output_parser\": output_parser,\n",
    "                                      #'prefix':PREFIX,\n",
    "                                      #'suffix':SUFFIX,\n",
    "                                      'format_instructions':customerized_instructions\n",
    "                                           })\n",
    "query = \"没有打tag的aws EC2实例有哪些？\"\n",
    "#query = \"安全组放开了80端口的aws EC2实例有哪些?\"\n",
    "inputs={\"input\":query}\n",
    "response = agent_executor.invoke(inputs)\n",
    "#print(\"agent response==\")\n",
    "#print(response)\n",
    "#stepMsgs = []\n",
    "#for index,step in enumerate(response[\"intermediate_steps\"]):\n",
    "#    print(\"step \"+str(index)+\"==\")\n",
    "#    print(step[0])\n",
    "#    #print(step.tool_input)\n",
    "#    #tool_name = step[0].tool\n",
    "#    #tool_input = step[0].tool_input\n",
    "#    #observation = step[1]\n",
    "#    #stepMsgs.append((tool_name,tool_input,observation))\n",
    "\n",
    "    \n",
    "\n",
    "#agent_executor.run(\"没有打tag的aws EC2实例有哪些？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a4209f7-6813-40de-9999-460911f7af97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output.truncate(0)\n",
    "del agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0c56a-8981-4f51-b1d9-29e0eded7524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
