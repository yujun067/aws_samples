{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1290f794-9477-4e45-ab20-81d04c040fc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## langcain agent demo for ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf80354-7edd-4403-9c8b-97a4712f4dcc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain[all]\n",
      "  Obtaining dependency information for langchain[all] from https://files.pythonhosted.org/packages/3d/e3/54fd72e0925988f1b7f957898869053c0df405cdbd46d891eb78a082311b/langchain-0.0.299-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.0.299-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain[all]) (6.0)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain[all])\n",
      "  Obtaining dependency information for SQLAlchemy<3,>=1.4 from https://files.pythonhosted.org/packages/99/f4/5c7868896285b0d95b6b3f0310850c6cf50b965569417c2959d2bd6a115d/SQLAlchemy-2.0.21-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.21-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.4 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain[all])\n",
      "  Obtaining dependency information for aiohttp<4.0.0,>=3.8.3 from https://files.pythonhosted.org/packages/3e/f6/fcda07dd1e72260989f0b22dde999ecfe80daa744f23ca167083683399bc/aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: anyio<4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain[all]) (3.7.1)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain[all])\n",
      "  Obtaining dependency information for async-timeout<5.0.0,>=4.0.0 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain[all])\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/13/75/82ce74880711ced796fd5a32e4d40c5a32dbea3f1c5e219a8b0544b7bd8c/dataclasses_json-0.6.0-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain[all])\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.38 (from langchain[all])\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.38 from https://files.pythonhosted.org/packages/f5/2d/bca3d01bbc128aa9b5c0134ad5f53955aa84a5620b6b07769ba75f7ca96c/langsmith-0.0.40-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.0.40-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting numexpr<3.0.0,>=2.8.4 (from langchain[all])\n",
      "  Obtaining dependency information for numexpr<3.0.0,>=2.8.4 from https://files.pythonhosted.org/packages/af/1f/a9bc507c4d53c0be52d2f1334dd79e13dc4663b64709b687a416506c2b86/numexpr-2.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading numexpr-2.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain[all]) (1.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain[all]) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain[all]) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain[all]) (8.2.2)\n",
      "Collecting O365<3.0.0,>=2.0.26 (from langchain[all])\n",
      "  Obtaining dependency information for O365<3.0.0,>=2.0.26 from https://files.pythonhosted.org/packages/b0/ad/c4fbf50c748ffe2d6b88f01673483185a73c0c1d1c29c59e85feae2c2c5b/O365-2.0.28-py3-none-any.whl.metadata\n",
      "  Downloading O365-2.0.28-py3-none-any.whl.metadata (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aleph-alpha-client<3.0.0,>=2.15.0 (from langchain[all])\n",
      "  Downloading aleph_alpha_client-2.17.0-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting amadeus>=8.1.0 (from langchain[all])\n",
      "  Downloading amadeus-9.0.0.tar.gz (39 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting arxiv<2.0,>=1.4 (from langchain[all])\n",
      "  Obtaining dependency information for arxiv<2.0,>=1.4 from https://files.pythonhosted.org/packages/f0/06/9b9d553d93e25ae27ec5ba794216afb1af248e43d85a35e922a85cbb396a/arxiv-1.4.8-py3-none-any.whl.metadata\n",
      "  Downloading arxiv-1.4.8-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting atlassian-python-api<4.0.0,>=3.36.0 (from langchain[all])\n",
      "  Obtaining dependency information for atlassian-python-api<4.0.0,>=3.36.0 from https://files.pythonhosted.org/packages/ca/ed/3577ccec639736c8e4660423be68cf1a4a7040bf543b3144793760792949/atlassian_python_api-3.41.2-py3-none-any.whl.metadata\n",
      "  Downloading atlassian_python_api-3.41.2-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting awadb<0.4.0,>=0.3.9 (from langchain[all])\n",
      "  Obtaining dependency information for awadb<0.4.0,>=0.3.9 from https://files.pythonhosted.org/packages/d8/6b/393bf502ba5805dc6321f8345da221637a6bd3938f0a6a8d92c50de1bdd4/awadb-0.3.10-cp310-cp310-manylinux1_x86_64.whl.metadata\n",
      "  Downloading awadb-0.3.10-cp310-cp310-manylinux1_x86_64.whl.metadata (368 bytes)\n",
      "Collecting azure-ai-formrecognizer<4.0.0,>=3.2.1 (from langchain[all])\n",
      "  Obtaining dependency information for azure-ai-formrecognizer<4.0.0,>=3.2.1 from https://files.pythonhosted.org/packages/ec/d6/255f4afed1e4d0e2aaf1b988d4c5ae453b65d9b92a3370634d7523804fd7/azure_ai_formrecognizer-3.3.0-py3-none-any.whl.metadata\n",
      "  Downloading azure_ai_formrecognizer-3.3.0-py3-none-any.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting azure-ai-vision<0.12.0,>=0.11.1b1 (from langchain[all])\n",
      "  Downloading azure_ai_vision-0.11.1b1-py3-none-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting azure-cognitiveservices-speech<2.0.0,>=1.28.0 (from langchain[all])\n",
      "  Obtaining dependency information for azure-cognitiveservices-speech<2.0.0,>=1.28.0 from https://files.pythonhosted.org/packages/01/b5/c33ef14e3b5a00d8d7f9fbcec686965aff352acd18070c26bba91b4223db/azure_cognitiveservices_speech-1.32.1-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading azure_cognitiveservices_speech-1.32.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting azure-cosmos<5.0.0,>=4.4.0b1 (from langchain[all])\n",
      "  Obtaining dependency information for azure-cosmos<5.0.0,>=4.4.0b1 from https://files.pythonhosted.org/packages/cd/66/c58f281d4650dc181f5d6df05ac673219f7e4071b3e2a0faa5afde2b0f61/azure_cosmos-4.5.1-py3-none-any.whl.metadata\n",
      "  Downloading azure_cosmos-4.5.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting azure-identity<2.0.0,>=1.12.0 (from langchain[all])\n",
      "  Obtaining dependency information for azure-identity<2.0.0,>=1.12.0 from https://files.pythonhosted.org/packages/42/8d/7701695ca568e373e6b8fa5193733b173ee8630f9b64843164b65a20f8c2/azure_identity-1.14.0-py3-none-any.whl.metadata\n",
      "  Downloading azure_identity-1.14.0-py3-none-any.whl.metadata (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m414.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4<5,>=4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain[all]) (4.12.2)\n",
      "Collecting clarifai>=9.1.0 (from langchain[all])\n",
      "  Obtaining dependency information for clarifai>=9.1.0 from https://files.pythonhosted.org/packages/85/32/3f48c95d9bb0c1d0d5b83753b1a8fe23a61665ea18e7c762f1c7a29830e6/clarifai-9.8.1-py3-none-any.whl.metadata\n",
      "  Downloading clarifai-9.8.1-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting clickhouse-connect<0.6.0,>=0.5.14 (from langchain[all])\n",
      "  Obtaining dependency information for clickhouse-connect<0.6.0,>=0.5.14 from https://files.pythonhosted.org/packages/ca/e7/dc68fb0cb8e49b2cc727ef224691aae021c47e543f1851ef8aae280c831b/clickhouse_connect-0.5.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading clickhouse_connect-0.5.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting cohere<5,>=4 (from langchain[all])\n",
      "  Obtaining dependency information for cohere<5,>=4 from https://files.pythonhosted.org/packages/db/35/6e4927c7aeb9ea426312cacf619cbd94fa9ac3cb1002cc6b6cd066180ce2/cohere-4.27-py3-none-any.whl.metadata\n",
      "  Downloading cohere-4.27-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting deeplake<4.0.0,>=3.6.8 (from langchain[all])\n",
      "  Downloading deeplake-3.6.26.tar.gz (547 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.5/547.5 kB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docarray[hnswlib]<0.33.0,>=0.32.0 (from langchain[all])\n",
      "  Obtaining dependency information for docarray[hnswlib]<0.33.0,>=0.32.0 from https://files.pythonhosted.org/packages/34/80/c6f9330b386ff76db35148cbd09fd882401b5d0468090b2bd8fb184254a4/docarray-0.32.1-py3-none-any.whl.metadata\n",
      "  Downloading docarray-0.32.1-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting duckduckgo-search<4.0.0,>=3.8.3 (from langchain[all])\n",
      "  Obtaining dependency information for duckduckgo-search<4.0.0,>=3.8.3 from https://files.pythonhosted.org/packages/26/37/0521e08bad7f2aee1253e942a182d115f4b480687d639765ccd7d79f0422/duckduckgo_search-3.8.5-py3-none-any.whl.metadata\n",
      "  Downloading duckduckgo_search-3.8.5-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting elasticsearch<9,>=8 (from langchain[all])\n",
      "  Obtaining dependency information for elasticsearch<9,>=8 from https://files.pythonhosted.org/packages/bb/06/81b1d71ba0567ff39d0f98f3637e810846df92f6733aee46004a194b51ea/elasticsearch-8.9.0-py3-none-any.whl.metadata\n",
      "  Downloading elasticsearch-8.9.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting esprima<5.0.0,>=4.0.1 (from langchain[all])\n",
      "  Downloading esprima-4.0.1.tar.gz (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting faiss-cpu<2,>=1 (from langchain[all])\n",
      "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-api-python-client==2.70.0 (from langchain[all])\n",
      "  Downloading google_api_python_client-2.70.0-py2.py3-none-any.whl (10.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3.0.0,>=2.18.1 (from langchain[all])\n",
      "  Obtaining dependency information for google-auth<3.0.0,>=2.18.1 from https://files.pythonhosted.org/packages/9d/44/5a992cb9d7bf8aaae73bc5adaf721ad08731c9d00c1c17999a8691404b0c/google_auth-2.23.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.23.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-search-results<3,>=2 (from langchain[all])\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gptcache>=0.1.7 (from langchain[all])\n",
      "  Obtaining dependency information for gptcache>=0.1.7 from https://files.pythonhosted.org/packages/66/55/0e51c3ee83ae3f922bd2da6a6e7cad8103750c44591c482800672d6278f1/gptcache-0.1.41-py3-none-any.whl.metadata\n",
      "  Downloading gptcache-0.1.41-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting html2text<2021.0.0,>=2020.1.16 (from langchain[all])\n",
      "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
      "Collecting huggingface_hub<1,>=0 (from langchain[all])\n",
      "  Obtaining dependency information for huggingface_hub<1,>=0 from https://files.pythonhosted.org/packages/72/21/51cddb8850ed3f4dbc21e57c3dabc49e64d5577857ddda7b2eb0ffc2ec0e/huggingface_hub-0.17.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.17.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jinja2<4,>=3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain[all]) (3.1.2)\n",
      "Collecting jq<2.0.0,>=1.4.1 (from langchain[all])\n",
      "  Obtaining dependency information for jq<2.0.0,>=1.4.1 from https://files.pythonhosted.org/packages/94/df/b93ac454a1db53980c261535f1a387bc7d0c92549429dfb2b016a9d6fdda/jq-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading jq-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting lancedb<0.2,>=0.1 (from langchain[all])\n",
      "  Obtaining dependency information for lancedb<0.2,>=0.1 from https://files.pythonhosted.org/packages/26/3a/a4d905258f6d868a43cb79fa62d517eac004936708128a379b51a29e0929/lancedb-0.1.16-py3-none-any.whl.metadata\n",
      "  Downloading lancedb-0.1.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langkit<0.1.0,>=0.0.6 (from langchain[all])\n",
      "  Obtaining dependency information for langkit<0.1.0,>=0.0.6 from https://files.pythonhosted.org/packages/01/2d/cc1d80ba25669145068241f025b37476651eef811d3d0e3a4a10d15aec6e/langkit-0.0.19-py3-none-any.whl.metadata\n",
      "  Downloading langkit-0.0.19-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting lark<2.0.0,>=1.1.5 (from langchain[all])\n",
      "  Obtaining dependency information for lark<2.0.0,>=1.1.5 from https://files.pythonhosted.org/packages/9a/16/54258d6b368db265bde53515fe7ccb7c261b4ff3591b6354531abfe922ef/lark-1.1.7-py3-none-any.whl.metadata\n",
      "  Downloading lark-1.1.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting libdeeplake<0.0.61,>=0.0.60 (from langchain[all])\n",
      "  Obtaining dependency information for libdeeplake<0.0.61,>=0.0.60 from https://files.pythonhosted.org/packages/0c/94/b6dc1fa02229285391982cd0b54bf79d2f43b37a753ec59332a80a2e9f46/libdeeplake-0.0.60-cp310-cp310-manylinux2010_x86_64.whl.metadata\n",
      "  Downloading libdeeplake-0.0.60-cp310-cp310-manylinux2010_x86_64.whl.metadata (326 bytes)\n",
      "Collecting librosa<0.11.0,>=0.10.0.post2 (from langchain[all])\n",
      "  Obtaining dependency information for librosa<0.11.0,>=0.10.0.post2 from https://files.pythonhosted.org/packages/e2/a2/4f639c1168d7aada749a896afb4892a831e2041bebdcf636aebfe9e86556/librosa-0.10.1-py3-none-any.whl.metadata\n",
      "  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting lxml<5.0.0,>=4.9.2 (from langchain[all])\n",
      "  Obtaining dependency information for lxml<5.0.0,>=4.9.2 from https://files.pythonhosted.org/packages/01/ae/ce23856fb6065f254101c1df381050b13adf26088dd554a15776615d470f/lxml-4.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata\n",
      "  Downloading lxml-4.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting manifest-ml<0.0.2,>=0.0.1 (from langchain[all])\n",
      "  Downloading manifest_ml-0.0.1-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting marqo<2.0.0,>=1.2.4 (from langchain[all])\n",
      "  Obtaining dependency information for marqo<2.0.0,>=1.2.4 from https://files.pythonhosted.org/packages/9e/8a/bc3bd770384fc00982b27204db0890747c9bfa31e052376b5adbc6bf7359/marqo-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading marqo-1.3.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting momento<2.0.0,>=1.5.0 (from langchain[all])\n",
      "  Obtaining dependency information for momento<2.0.0,>=1.5.0 from https://files.pythonhosted.org/packages/5b/17/e8db0d674f4553ce59aa58f2c5f00b7b5364b42294e3dd21a77986b55e97/momento-1.9.2-py3-none-any.whl.metadata\n",
      "  Downloading momento-1.9.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting nebula3-python<4.0.0,>=3.4.0 (from langchain[all])\n",
      "  Downloading nebula3_python-3.4.0-py3-none-any.whl (312 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.4/312.4 kB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting neo4j<6.0.0,>=5.8.1 (from langchain[all])\n",
      "  Downloading neo4j-5.12.0.tar.gz (190 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting networkx<3.0.0,>=2.6.3 (from langchain[all])\n",
      "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nlpcloud<2,>=1 (from langchain[all])\n",
      "  Obtaining dependency information for nlpcloud<2,>=1 from https://files.pythonhosted.org/packages/9b/0c/efb6d94ae955ce766084c2527775a9cf6e72b92571ccce83a7b26ec6882e/nlpcloud-1.1.44-py3-none-any.whl.metadata\n",
      "  Downloading nlpcloud-1.1.44-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting nltk<4,>=3 (from langchain[all])\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nomic<2.0.0,>=1.0.43 (from langchain[all])\n",
      "  Downloading nomic-1.1.14.tar.gz (31 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting openai<1,>=0 (from langchain[all])\n",
      "  Obtaining dependency information for openai<1,>=0 from https://files.pythonhosted.org/packages/ae/59/911d6e5f1d7514d79c527067643376cddcf4cb8d1728e599b3b03ab51c69/openai-0.28.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting openlm<0.0.6,>=0.0.5 (from langchain[all])\n",
      "  Obtaining dependency information for openlm<0.0.6,>=0.0.5 from https://files.pythonhosted.org/packages/7f/80/756e132b07d32c7fcb8211321fedeb0b9dc33d6d771dbefbf71623605003/openlm-0.0.5-py3-none-any.whl.metadata\n",
      "  Downloading openlm-0.0.5-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting opensearch-py<3.0.0,>=2.0.0 (from langchain[all])\n",
      "  Obtaining dependency information for opensearch-py<3.0.0,>=2.0.0 from https://files.pythonhosted.org/packages/23/a1/18afd74d63ad21978d506b59f6d1bfa028463cff20bdd7dd59ff62087738/opensearch_py-2.3.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading opensearch_py-2.3.1-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pdfminer-six<20221106,>=20221105 (from langchain[all])\n",
      "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pexpect<5.0.0,>=4.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain[all]) (4.8.0)\n",
      "Collecting pgvector<0.2.0,>=0.1.6 (from langchain[all])\n",
      "  Obtaining dependency information for pgvector<0.2.0,>=0.1.6 from https://files.pythonhosted.org/packages/1b/2a/3c7af6b8460d931102cb67709b870e535c5afad3e00639ffef3f408989a5/pgvector-0.1.8-py2.py3-none-any.whl.metadata\n",
      "  Downloading pgvector-0.1.8-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pinecone-client<3,>=2 (from langchain[all])\n",
      "  Obtaining dependency information for pinecone-client<3,>=2 from https://files.pythonhosted.org/packages/df/d4/cffbb61236c6c1d7510e835c1ff843e4e7d705ed59d21c0e5b6dc1cb4fd8/pinecone_client-2.2.4-py3-none-any.whl.metadata\n",
      "  Downloading pinecone_client-2.2.4-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting pinecone-text<0.5.0,>=0.4.2 (from langchain[all])\n",
      "  Downloading pinecone_text-0.4.2-py3-none-any.whl (17 kB)\n",
      "Collecting psycopg2-binary<3.0.0,>=2.9.5 (from langchain[all])\n",
      "  Obtaining dependency information for psycopg2-binary<3.0.0,>=2.9.5 from https://files.pythonhosted.org/packages/e3/b2/f578b59b83563648c7224bae9397dc4bab6fe2dd2b4338786bb7e373bc4a/psycopg2_binary-2.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading psycopg2_binary-2.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting pymongo<5.0.0,>=4.3.3 (from langchain[all])\n",
      "  Obtaining dependency information for pymongo<5.0.0,>=4.3.3 from https://files.pythonhosted.org/packages/4e/50/7e0e838892507d99a6b981824c73617cba567a56a802a518d49e12da77b6/pymongo-4.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pymongo-4.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Collecting pyowm<4.0.0,>=3.3.0 (from langchain[all])\n",
      "  Downloading pyowm-3.3.0-py3-none-any.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pypdf<4.0.0,>=3.4.0 (from langchain[all])\n",
      "  Obtaining dependency information for pypdf<4.0.0,>=3.4.0 from https://files.pythonhosted.org/packages/92/a1/4af912cb0cbde61dc7ba898c06b145be63e46a23cd3e09f83a179af60705/pypdf-3.16.1-py3-none-any.whl.metadata\n",
      "  Downloading pypdf-3.16.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting pytesseract<0.4.0,>=0.3.10 (from langchain[all])\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Collecting python-arango<8.0.0,>=7.5.9 (from langchain[all])\n",
      "  Obtaining dependency information for python-arango<8.0.0,>=7.5.9 from https://files.pythonhosted.org/packages/70/ee/945d1c22c6bcde09ea3a68f55383ad801cb9d17794c2edc6ef5dcbaaedcd/python_arango-7.6.2-py3-none-any.whl.metadata\n",
      "  Downloading python_arango-7.6.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting pyvespa<0.34.0,>=0.33.0 (from langchain[all])\n",
      "  Downloading pyvespa-0.33.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting qdrant-client<2.0.0,>=1.3.1 (from langchain[all])\n",
      "  Obtaining dependency information for qdrant-client<2.0.0,>=1.3.1 from https://files.pythonhosted.org/packages/ea/58/821a9abb42e9a1fe4a50336d9147afd8c6259b96b8464c5d07697341f6ec/qdrant_client-1.5.4-py3-none-any.whl.metadata\n",
      "  Downloading qdrant_client-1.5.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting rdflib<7.0.0,>=6.3.2 (from langchain[all])\n",
      "  Downloading rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting redis<5,>=4 (from langchain[all])\n",
      "  Obtaining dependency information for redis<5,>=4 from https://files.pythonhosted.org/packages/20/2e/409703d645363352a20c944f5d119bdae3eb3034051a53724a7c5fee12b8/redis-4.6.0-py3-none-any.whl.metadata\n",
      "  Downloading redis-4.6.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langchain[all])\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentence-transformers<3,>=2 (from langchain[all])\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting singlestoredb<0.8.0,>=0.7.1 (from langchain[all])\n",
      "  Obtaining dependency information for singlestoredb<0.8.0,>=0.7.1 from https://files.pythonhosted.org/packages/03/42/d630685a46e0494c9caab1661ea71a9f81740419126964854957c57c129f/singlestoredb-0.7.1-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading singlestoredb-0.7.1-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
      "Collecting tensorflow-text<3.0.0,>=2.11.0 (from langchain[all])\n",
      "  Obtaining dependency information for tensorflow-text<3.0.0,>=2.11.0 from https://files.pythonhosted.org/packages/c3/04/01e331424b02c88bce2a71d498fbf2507832b3289f2ac71f466a06e81aee/tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting tigrisdb<2.0.0,>=1.0.0b6 (from langchain[all])\n",
      "  Obtaining dependency information for tigrisdb<2.0.0,>=1.0.0b6 from https://files.pythonhosted.org/packages/b2/b1/39b47da56e42ad72814dae89e36cb96ea7ff75a0672b92b159bcc4d63f2f/tigrisdb-1.0.0b6-py3-none-any.whl.metadata\n",
      "  Downloading tigrisdb-1.0.0b6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting tiktoken<0.4.0,>=0.3.2 (from langchain[all])\n",
      "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch<3,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain[all]) (2.0.1)\n",
      "Collecting transformers<5,>=4 (from langchain[all])\n",
      "  Obtaining dependency information for transformers<5,>=4 from https://files.pythonhosted.org/packages/1a/06/3817f9bb923437ead9a794f0ac0d03b8b5e0478ab112db4c413dd37c09da/transformers-4.33.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.33.2-py3-none-any.whl.metadata (119 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting weaviate-client<4,>=3 (from langchain[all])\n",
      "  Obtaining dependency information for weaviate-client<4,>=3 from https://files.pythonhosted.org/packages/59/8f/44d164ed990f7c6faf28125925160af9004595020aeaaf01e94462e3bf8e/weaviate_client-3.24.1-py3-none-any.whl.metadata\n",
      "  Downloading weaviate_client-3.24.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting wikipedia<2,>=1 (from langchain[all])\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting wolframalpha==5.0.0 (from langchain[all])\n",
      "  Downloading wolframalpha-5.0.0-py3-none-any.whl (7.5 kB)\n",
      "Collecting httplib2<1dev,>=0.15.0 (from google-api-python-client==2.70.0->langchain[all])\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-httplib2>=0.1.0 (from google-api-python-client==2.70.0->langchain[all])\n",
      "  Obtaining dependency information for google-auth-httplib2>=0.1.0 from https://files.pythonhosted.org/packages/d3/3d/e4991229886c0d522d9552151a43ff7adcc61e026e60ce8bd508387f84cf/google_auth_httplib2-0.1.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth_httplib2-0.1.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 (from google-api-python-client==2.70.0->langchain[all])\n",
      "  Obtaining dependency information for google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 from https://files.pythonhosted.org/packages/6e/c4/c3cd048b6cbeba8d9ae50dd7643ac065b85237338aa7501b0efae91eb4d9/google_api_core-2.11.1-py3-none-any.whl.metadata\n",
      "  Downloading google_api_core-2.11.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client==2.70.0->langchain[all])\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting xmltodict (from wolframalpha==5.0.0->langchain[all])\n",
      "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
      "Collecting more-itertools (from wolframalpha==5.0.0->langchain[all])\n",
      "  Obtaining dependency information for more-itertools from https://files.pythonhosted.org/packages/5a/cb/6dce742ea14e47d6f565589e859ad225f2a5de576d7696e0623b784e226b/more_itertools-10.1.0-py3-none-any.whl.metadata\n",
      "  Downloading more_itertools-10.1.0-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting jaraco.context (from wolframalpha==5.0.0->langchain[all])\n",
      "  Downloading jaraco.context-4.3.0-py3-none-any.whl (5.3 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain[all]) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain[all]) (3.2.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain[all])\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain[all])\n",
      "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain[all])\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/1e/28/74b8b6451c89c070d34e753d8b65a1e4ce508a6808b18529f36e8c0e2184/frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain[all])\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: urllib3>=1.26 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aleph-alpha-client<3.0.0,>=2.15.0->langchain[all]) (1.26.14)\n",
      "Collecting aiodns>=3.0.0 (from aleph-alpha-client<3.0.0,>=2.15.0->langchain[all])\n",
      "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
      "Collecting aiohttp-retry>=2.8.3 (from aleph-alpha-client<3.0.0,>=2.15.0->langchain[all])\n",
      "  Downloading aiohttp_retry-2.8.3-py3-none-any.whl (9.8 kB)\n",
      "Collecting tokenizers>=0.13.2 (from aleph-alpha-client<3.0.0,>=2.15.0->langchain[all])\n",
      "  Obtaining dependency information for tokenizers>=0.13.2 from https://files.pythonhosted.org/packages/57/bd/45b5ef6b088880779f70acf60027f7043ca5fa1b98f4a4345cf3aea09044/tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aleph-alpha-client<3.0.0,>=2.15.0->langchain[all]) (4.7.1)\n",
      "Requirement already satisfied: Pillow>=9.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aleph-alpha-client<3.0.0,>=2.15.0->langchain[all]) (10.0.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4.0->langchain[all]) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4.0->langchain[all]) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4.0->langchain[all]) (1.1.2)\n",
      "Collecting feedparser (from arxiv<2.0,>=1.4->langchain[all])\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting deprecated (from atlassian-python-api<4.0.0,>=3.36.0->langchain[all])\n",
      "  Obtaining dependency information for deprecated from https://files.pythonhosted.org/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl.metadata\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from atlassian-python-api<4.0.0,>=3.36.0->langchain[all]) (1.16.0)\n",
      "Collecting oauthlib (from atlassian-python-api<4.0.0,>=3.36.0->langchain[all])\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib (from atlassian-python-api<4.0.0,>=3.36.0->langchain[all])\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting azure-core<2.0.0,>=1.23.0 (from azure-ai-formrecognizer<4.0.0,>=3.2.1->langchain[all])\n",
      "  Obtaining dependency information for azure-core<2.0.0,>=1.23.0 from https://files.pythonhosted.org/packages/98/3a/d53e2b8a75c448ef45d7ae4b0659eb6c0d48978f25a709e2a39894a48704/azure_core-1.29.4-py3-none-any.whl.metadata\n",
      "  Downloading azure_core-1.29.4-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting msrest>=0.6.21 (from azure-ai-formrecognizer<4.0.0,>=3.2.1->langchain[all])\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting azure-common~=1.1 (from azure-ai-formrecognizer<4.0.0,>=3.2.1->langchain[all])\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from azure-identity<2.0.0,>=1.12.0->langchain[all]) (41.0.2)\n",
      "Collecting msal<2.0.0,>=1.20.0 (from azure-identity<2.0.0,>=1.12.0->langchain[all])\n",
      "  Obtaining dependency information for msal<2.0.0,>=1.20.0 from https://files.pythonhosted.org/packages/8f/71/5c385d104814fede34da5e10102bc0f4a0d05ef42eae052dac787381b2bc/msal-1.24.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading msal-1.24.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions<2.0.0,>=0.3.0 (from azure-identity<2.0.0,>=1.12.0->langchain[all])\n",
      "  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from beautifulsoup4<5,>=4->langchain[all]) (2.3.2.post1)\n",
      "Collecting clarifai-grpc>=9.8.1 (from clarifai>=9.1.0->langchain[all])\n",
      "  Obtaining dependency information for clarifai-grpc>=9.8.1 from https://files.pythonhosted.org/packages/32/2f/6fb19317eb9c7d817b0452327b2e68af8f1981b99b07ee0e6e4f2519ac81/clarifai_grpc-9.8.3-py3-none-any.whl.metadata\n",
      "  Downloading clarifai_grpc-9.8.3-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting tritonclient==2.34.0 (from clarifai>=9.1.0->langchain[all])\n",
      "  Obtaining dependency information for tritonclient==2.34.0 from https://files.pythonhosted.org/packages/f6/cb/8a8bf5641ce55b29fdeb1ce5bce38c6e53c96a9b864f23ed0ccbbe803920/tritonclient-2.34.0-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading tritonclient-2.34.0-py3-none-manylinux1_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from clarifai>=9.1.0->langchain[all]) (21.3)\n",
      "Collecting tqdm==4.64.1 (from clarifai>=9.1.0->langchain[all])\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rich==13.4.2 (from clarifai>=9.1.0->langchain[all])\n",
      "  Obtaining dependency information for rich==13.4.2 from https://files.pythonhosted.org/packages/fc/1e/482e5eec0b89b593e81d78f819a9412849814e22225842b598908e7ac560/rich-13.4.2-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.4.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich==13.4.2->clarifai>=9.1.0->langchain[all])\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich==13.4.2->clarifai>=9.1.0->langchain[all]) (2.15.1)\n",
      "Collecting python-rapidjson>=0.9.1 (from tritonclient==2.34.0->clarifai>=9.1.0->langchain[all])\n",
      "  Obtaining dependency information for python-rapidjson>=0.9.1 from https://files.pythonhosted.org/packages/f9/bc/cf6666989a2d6e8cceec31fa0cf9235bf4aaa05d1e35a3a40ef552dab0bc/python_rapidjson-1.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading python_rapidjson-1.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from clickhouse-connect<0.6.0,>=0.5.14->langchain[all]) (2023.5.7)\n",
      "Requirement already satisfied: pytz in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from clickhouse-connect<0.6.0,>=0.5.14->langchain[all]) (2023.3)\n",
      "Collecting zstandard (from clickhouse-connect<0.6.0,>=0.5.14->langchain[all])\n",
      "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting lz4 (from clickhouse-connect<0.6.0,>=0.5.14->langchain[all])\n",
      "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting backoff<3.0,>=2.0 (from cohere<5,>=4->langchain[all])\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting fastavro==1.8.2 (from cohere<5,>=4->langchain[all])\n",
      "  Obtaining dependency information for fastavro==1.8.2 from https://files.pythonhosted.org/packages/43/96/8cecc293becb041c0a6106d9b4cd8295f9eff30f883731204c3ca43813f2/fastavro-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading fastavro-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from cohere<5,>=4->langchain[all]) (6.8.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain[all])\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/ed/3c/cebfdcad015240014ff08b883d1c0c427f2ba45ae8c6572851b6ef136cad/marshmallow-3.20.1-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain[all])\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from deeplake<4.0.0,>=3.6.8->langchain[all]) (1.28.41)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from deeplake<4.0.0,>=3.6.8->langchain[all]) (8.1.6)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from deeplake<4.0.0,>=3.6.8->langchain[all]) (0.3.0)\n",
      "Collecting humbug>=0.3.1 (from deeplake<4.0.0,>=3.6.8->langchain[all])\n",
      "  Obtaining dependency information for humbug>=0.3.1 from https://files.pythonhosted.org/packages/c8/cc/c8129d6e9a1f473b5e90cf1b8eac43191a22657b9b673e02815548662270/humbug-0.3.2-py3-none-any.whl.metadata\n",
      "  Downloading humbug-0.3.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting numcodecs (from deeplake<4.0.0,>=3.6.8->langchain[all])\n",
      "  Downloading numcodecs-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyjwt (from deeplake<4.0.0,>=3.6.8->langchain[all])\n",
      "  Obtaining dependency information for pyjwt from https://files.pythonhosted.org/packages/2b/4f/e04a8067c7c96c364cef7ef73906504e2f40d690811c021e1a1901473a19/PyJWT-2.8.0-py3-none-any.whl.metadata\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting aioboto3>=10.4.0 (from deeplake<4.0.0,>=3.6.8->langchain[all])\n",
      "  Obtaining dependency information for aioboto3>=10.4.0 from https://files.pythonhosted.org/packages/56/31/9d802c23743f0ae2bd48d29102bcfafe2d4b27ade86cbe67a190582527e9/aioboto3-11.3.0-py3-none-any.whl.metadata\n",
      "  Downloading aioboto3-11.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: nest-asyncio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from deeplake<4.0.0,>=3.6.8->langchain[all]) (1.5.5)\n",
      "Collecting orjson>=3.8.2 (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[all])\n",
      "  Obtaining dependency information for orjson>=3.8.2 from https://files.pythonhosted.org/packages/5d/2a/7719c0e6a812037d3de563f34fd7c854933b2bcade98ea5ab11230c0b735/orjson-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading orjson-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting types-requests>=2.28.11.6 (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[all])\n",
      "  Obtaining dependency information for types-requests>=2.28.11.6 from https://files.pythonhosted.org/packages/59/61/31ce2823d0b50c9067dd8ac8606df6a68b05f06adcf60ed85c4d122a3626/types_requests-2.31.0.3-py3-none-any.whl.metadata\n",
      "  Downloading types_requests-2.31.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting hnswlib>=0.6.2 (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[all])\n",
      "  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.19.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[all]) (4.23.4)\n",
      "Collecting aiofiles>=23.1.0 (from duckduckgo-search<4.0.0,>=3.8.3->langchain[all])\n",
      "  Obtaining dependency information for aiofiles>=23.1.0 from https://files.pythonhosted.org/packages/c5/19/5af6804c4cc0fed83f47bff6e413a98a36618e7d40185cd36e69737f3b0e/aiofiles-23.2.1-py3-none-any.whl.metadata\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting httpx[brotli,http2,socks]>=0.24.1 (from duckduckgo-search<4.0.0,>=3.8.3->langchain[all])\n",
      "  Obtaining dependency information for httpx[brotli,http2,socks]>=0.24.1 from https://files.pythonhosted.org/packages/33/0d/d9ce469af019741c8999711d36b270ff992ceb1a0293f73f9f34fdf131e9/httpx-0.25.0-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.25.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting elastic-transport<9,>=8 (from elasticsearch<9,>=8->langchain[all])\n",
      "  Downloading elastic_transport-8.4.0-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0,>=2.18.1->langchain[all])\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a9/c9/c8a7710f2cedcb1db9224fdd4d8307c9e48cbddc46c18b515fefc0f1abbe/cachetools-5.3.1-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.18.1->langchain[all])\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.18.1->langchain[all]) (4.7.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<1,>=0->langchain[all]) (3.12.2)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface_hub<1,>=0->langchain[all]) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2<4,>=3->langchain[all]) (2.1.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain[all]) (2.4)\n",
      "Collecting pylance==0.5.10 (from lancedb<0.2,>=0.1->langchain[all])\n",
      "  Obtaining dependency information for pylance==0.5.10 from https://files.pythonhosted.org/packages/79/33/c9a15273de803603ff7602c4e1c26f3878ea8ddd39f0f9c658f75c8261e5/pylance-0.5.10-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pylance-0.5.10-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting ratelimiter (from lancedb<0.2,>=0.1->langchain[all])\n",
      "  Downloading ratelimiter-1.2.0.post0-py3-none-any.whl (6.6 kB)\n",
      "Collecting retry (from lancedb<0.2,>=0.1->langchain[all])\n",
      "  Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
      "Collecting attr (from lancedb<0.2,>=0.1->langchain[all])\n",
      "  Downloading attr-0.3.2-py2.py3-none-any.whl (3.3 kB)\n",
      "Collecting semver (from lancedb<0.2,>=0.1->langchain[all])\n",
      "  Obtaining dependency information for semver from https://files.pythonhosted.org/packages/d4/5d/f2b4fe45886238c405ad177ca43911cb1459d08003004da5c27495eb4216/semver-3.0.1-py3-none-any.whl.metadata\n",
      "  Downloading semver-3.0.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pyarrow>=10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pylance==0.5.10->lancedb<0.2,>=0.1->langchain[all]) (12.0.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langkit<0.1.0,>=0.0.6->langchain[all]) (1.5.3)\n",
      "Collecting textstat<0.8.0,>=0.7.3 (from langkit<0.1.0,>=0.0.6->langchain[all])\n",
      "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting whylogs==1.2.6 (from langkit<0.1.0,>=0.0.6->langchain[all])\n",
      "  Obtaining dependency information for whylogs==1.2.6 from https://files.pythonhosted.org/packages/07/10/cd37536c5145a3053ef6d4dd6a4067a58ce795be8313380fc1492e89a65c/whylogs-1.2.6-py3-none-any.whl.metadata\n",
      "  Downloading whylogs-1.2.6-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: platformdirs<4.0.0,>=3.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from whylogs==1.2.6->langkit<0.1.0,>=0.0.6->langchain[all]) (3.9.1)\n",
      "Collecting whylabs-client<1,>=0.5.1 (from whylogs==1.2.6->langkit<0.1.0,>=0.0.6->langchain[all])\n",
      "  Obtaining dependency information for whylabs-client<1,>=0.5.1 from https://files.pythonhosted.org/packages/61/37/56de38d4f107ed5f1f02a036007100c607cb2b210ce86ddd9fd37ecfeb69/whylabs_client-0.5.7-py3-none-any.whl.metadata\n",
      "  Downloading whylabs_client-0.5.7-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting whylogs-sketching>=3.4.1.dev3 (from whylogs==1.2.6->langkit<0.1.0,>=0.0.6->langchain[all])\n",
      "  Downloading whylogs_sketching-3.4.1.dev3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (547 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.3/547.3 kB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting audioread>=2.1.9 (from librosa<0.11.0,>=0.10.0.post2->langchain[all])\n",
      "  Downloading audioread-3.0.0.tar.gz (377 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa<0.11.0,>=0.10.0.post2->langchain[all]) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa<0.11.0,>=0.10.0.post2->langchain[all]) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa<0.11.0,>=0.10.0.post2->langchain[all]) (1.3.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa<0.11.0,>=0.10.0.post2->langchain[all]) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa<0.11.0,>=0.10.0.post2->langchain[all]) (0.57.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa<0.11.0,>=0.10.0.post2->langchain[all])\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_17_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pooch>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa<0.11.0,>=0.10.0.post2->langchain[all]) (1.7.0)\n",
      "Collecting soxr>=0.3.2 (from librosa<0.11.0,>=0.10.0.post2->langchain[all])\n",
      "  Obtaining dependency information for soxr>=0.3.2 from https://files.pythonhosted.org/packages/c0/ef/12d855b465dc3d85d5c53c666e8963f87557d50bfad68d26cb16348b3747/soxr-0.3.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading soxr-0.3.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting lazy-loader>=0.1 (from librosa<0.11.0,>=0.10.0.post2->langchain[all])\n",
      "  Obtaining dependency information for lazy-loader>=0.1 from https://files.pythonhosted.org/packages/a1/c3/65b3814e155836acacf720e5be3b5757130346670ac454fee29d3eda1381/lazy_loader-0.3-py3-none-any.whl.metadata\n",
      "  Downloading lazy_loader-0.3-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting msgpack>=1.0 (from librosa<0.11.0,>=0.10.0.post2->langchain[all])\n",
      "  Obtaining dependency information for msgpack>=1.0 from https://files.pythonhosted.org/packages/92/cb/fb176f840b8ead860fd7ac2060dbc26f2ccc551d5a08e590ea979de4b63a/msgpack-1.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading msgpack-1.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: dill>=0.3.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from manifest-ml<0.0.2,>=0.0.1->langchain[all]) (0.3.6)\n",
      "Collecting sqlitedict>=2.0.0 (from manifest-ml<0.0.2,>=0.0.1->langchain[all])\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pydantic<3,>=1 (from langchain[all])\n",
      "  Obtaining dependency information for pydantic<3,>=1 from https://files.pythonhosted.org/packages/bc/e0/0371e9b6c910afe502e5fe18cc94562bfd9399617c7b4f5b6e13c29115b3/pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.3/149.3 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0.0,>=1.46.0 (from momento<2.0.0,>=1.5.0->langchain[all])\n",
      "  Obtaining dependency information for grpcio<2.0.0,>=1.46.0 from https://files.pythonhosted.org/packages/28/94/63bef715d0afea96662c66075d72249bf9b55b018b91b6937045bdc1470c/grpcio-1.58.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading grpcio-1.58.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting momento-wire-types<0.76.0,>=0.75.0 (from momento<2.0.0,>=1.5.0->langchain[all])\n",
      "  Obtaining dependency information for momento-wire-types<0.76.0,>=0.75.0 from https://files.pythonhosted.org/packages/89/a6/b0f7c1d0495ca97646f859e71702b6d173028f33a703207baa0af7d9d955/momento_wire_types-0.75.0-py3-none-any.whl.metadata\n",
      "  Downloading momento_wire_types-0.75.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting future>=0.18.0 (from nebula3-python<4.0.0,>=3.4.0->langchain[all])\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting regex>=2021.8.3 (from nltk<4,>=3->langchain[all])\n",
      "  Obtaining dependency information for regex>=2021.8.3 from https://files.pythonhosted.org/packages/d1/df/460ca6171a8494fcf37af43f52f6fac23e38784bb4a26563f6fa01ef6faf/regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jsonlines (from nomic<2.0.0,>=1.0.43->langchain[all])\n",
      "  Obtaining dependency information for jsonlines from https://files.pythonhosted.org/packages/f8/62/d9ba6323b9202dd2fe166beab8a86d29465c41a0288cbe229fac60c1ab8d/jsonlines-4.0.0-py3-none-any.whl.metadata\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting loguru (from nomic<2.0.0,>=1.0.43->langchain[all])\n",
      "  Obtaining dependency information for loguru from https://files.pythonhosted.org/packages/03/0a/4f6fed21aa246c6b49b561ca55facacc2a44b87d65b8b92362a8e99ba202/loguru-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting wonderwords (from nomic<2.0.0,>=1.0.43->langchain[all])\n",
      "  Downloading wonderwords-2.2.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from O365<3.0.0,>=2.0.26->langchain[all]) (2.8.2)\n",
      "Collecting tzlocal<5.0,>=4.0 (from O365<3.0.0,>=2.0.26->langchain[all])\n",
      "  Obtaining dependency information for tzlocal<5.0,>=4.0 from https://files.pythonhosted.org/packages/55/a6/a75af44665e5e77e52f6789eef4f8bc056c8e039d96c804b975806942580/tzlocal-4.3.1-py3-none-any.whl.metadata\n",
      "  Downloading tzlocal-4.3.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting stringcase>=1.2.0 (from O365<3.0.0,>=2.0.26->langchain[all])\n",
      "  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pexpect<5.0.0,>=4.8.0->langchain[all]) (0.7.0)\n",
      "Collecting dnspython>=2.0.0 (from pinecone-client<3,>=2->langchain[all])\n",
      "  Obtaining dependency information for dnspython>=2.0.0 from https://files.pythonhosted.org/packages/f6/b4/0a9bee52c50f226a3cbfb54263d02bb421c7f2adc136520729c2c689c1e5/dnspython-2.4.2-py3-none-any.whl.metadata\n",
      "  Downloading dnspython-2.4.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting mmh3<4.0.0,>=3.1.0 (from pinecone-text<0.5.0,>=0.4.2->langchain[all])\n",
      "  Downloading mmh3-3.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38 kB)\n",
      "Collecting torch<3,>=1 (from langchain[all])\n",
      "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m482.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting wget<4.0,>=3.2 (from pinecone-text<0.5.0,>=0.4.2->langchain[all])\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting geojson<3,>=2.3.0 (from pyowm<4.0.0,>=3.3.0->langchain[all])\n",
      "  Downloading geojson-2.5.0-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: PySocks<2,>=1.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pyowm<4.0.0,>=3.3.0->langchain[all]) (1.7.1)\n",
      "Requirement already satisfied: setuptools>=42 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-arango<8.0.0,>=7.5.9->langchain[all]) (68.0.0)\n",
      "Collecting packaging (from clarifai>=9.1.0->langchain[all])\n",
      "  Using cached packaging-23.1-py3-none-any.whl (48 kB)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pyvespa<0.34.0,>=0.33.0->langchain[all]) (6.1.3)\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.3.1->langchain[all])\n",
      "  Obtaining dependency information for grpcio-tools>=1.41.0 from https://files.pythonhosted.org/packages/b1/a3/9e36738ab61adae1f775c6e988a788b8f597b9e9b8bc6cc16a23c4d7a937/grpcio_tools-1.58.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading grpcio_tools-1.58.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client<2.0.0,>=1.3.1->langchain[all])\n",
      "  Obtaining dependency information for portalocker<3.0.0,>=2.7.0 from https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl.metadata\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting isodate<0.7.0,>=0.6.0 (from rdflib<7.0.0,>=6.3.2->langchain[all])\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing<4,>=2.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rdflib<7.0.0,>=6.3.2->langchain[all]) (3.0.9)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence-transformers<3,>=2->langchain[all]) (0.15.2)\n",
      "Collecting sentencepiece (from sentence-transformers<3,>=2->langchain[all])\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting build (from singlestoredb<0.8.0,>=0.7.1->langchain[all])\n",
      "  Obtaining dependency information for build from https://files.pythonhosted.org/packages/93/dd/b464b728b866aaa62785a609e0dd8c72201d62c5f7c53e7c20f4dceb085f/build-1.0.3-py3-none-any.whl.metadata\n",
      "  Downloading build-1.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting sqlparams (from singlestoredb<0.8.0,>=0.7.1->langchain[all])\n",
      "  Downloading sqlparams-5.1.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from singlestoredb<0.8.0,>=0.7.1->langchain[all]) (0.40.0)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain[all])\n",
      "  Downloading greenlet-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (613 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.7/613.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-hub>=0.8.0 (from tensorflow-text<3.0.0,>=2.11.0->langchain[all])\n",
      "  Obtaining dependency information for tensorflow-hub>=0.8.0 from https://files.pythonhosted.org/packages/30/78/9d5292a2b616901bdb075bbf0c777b293f4140bb48108ac2b33fd716c2eb/tensorflow_hub-0.14.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_hub-0.14.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tensorflow<2.14,>=2.13.0 (from tensorflow-text<3.0.0,>=2.11.0->langchain[all])\n",
      "  Obtaining dependency information for tensorflow<2.14,>=2.13.0 from https://files.pythonhosted.org/packages/5a/f2/5c2f878c62c8b79c629b11b33516bb55054d7677eba6f56f3a20296b56bd/tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<3,>=1->langchain[all])\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch<3,>=1->langchain[all])\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch<3,>=1->langchain[all])\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<3,>=1->langchain[all])\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers>=0.13.2 (from aleph-alpha-client<3.0.0,>=2.15.0->langchain[all])\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5,>=4->langchain[all])\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/6c/f0/c17bbdb1e5f9dab29d44cade445135789f75f8f08ea2728d04493ea8412b/safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting validators<1.0.0,>=0.21.2 (from weaviate-client<4,>=3->langchain[all])\n",
      "  Obtaining dependency information for validators<1.0.0,>=0.21.2 from https://files.pythonhosted.org/packages/3a/0c/785d317eea99c3739821718f118c70537639aa43f96bfa1d83a71f68eaf6/validators-0.22.0-py3-none-any.whl.metadata\n",
      "  Downloading validators-0.22.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting authlib<2.0.0,>=1.2.1 (from weaviate-client<4,>=3->langchain[all])\n",
      "  Obtaining dependency information for authlib<2.0.0,>=1.2.1 from https://files.pythonhosted.org/packages/81/6e/f4522542322c7f53783da5f65464a7dee137c687111624d2ac733e2a1b98/Authlib-1.2.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading Authlib-1.2.1-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting aiobotocore[boto3]==2.6.0 (from aioboto3>=10.4.0->deeplake<4.0.0,>=3.6.8->langchain[all])\n",
      "  Obtaining dependency information for aiobotocore[boto3]==2.6.0 from https://files.pythonhosted.org/packages/30/f5/495f81a2bb24f5b876cadb84be802d4dbf0c5707aa8e9102614444b4cd05/aiobotocore-2.6.0-py3-none-any.whl.metadata\n",
      "  Downloading aiobotocore-2.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting botocore<1.31.18,>=1.31.17 (from aiobotocore[boto3]==2.6.0->aioboto3>=10.4.0->deeplake<4.0.0,>=3.6.8->langchain[all])\n",
      "  Obtaining dependency information for botocore<1.31.18,>=1.31.17 from https://files.pythonhosted.org/packages/3d/e5/32a88f5a95e3d43c2e3ed86fc1ffdb715547a04f95a51d00e1185af63b0c/botocore-1.31.17-py3-none-any.whl.metadata\n",
      "  Downloading botocore-1.31.17-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting wrapt<2.0.0,>=1.10.10 (from aiobotocore[boto3]==2.6.0->aioboto3>=10.4.0->deeplake<4.0.0,>=3.6.8->langchain[all])\n",
      "  Downloading wrapt-1.15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m960.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore[boto3]==2.6.0->aioboto3>=10.4.0->deeplake<4.0.0,>=3.6.8->langchain[all])\n",
      "  Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
      "Collecting boto3 (from deeplake<4.0.0,>=3.6.8->langchain[all])\n",
      "  Obtaining dependency information for boto3 from https://files.pythonhosted.org/packages/46/a7/487512e3328f2566d72aed3b7059fd8dff18c95d9bcbbe16c5ecc13e6fc5/boto3-1.28.17-py3-none-any.whl.metadata\n",
      "  Downloading boto3-1.28.17-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting pycares>=4.0.0 (from aiodns>=3.0.0->aleph-alpha-client<3.0.0,>=2.15.0->langchain[all])\n",
      "  Downloading pycares-4.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.7/288.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3->deeplake<4.0.0,>=3.6.8->langchain[all]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3->deeplake<4.0.0,>=3.6.8->langchain[all]) (0.6.1)\n",
      "Collecting googleapis-common-protos>=1.53.0 (from clarifai-grpc>=9.8.1->clarifai>=9.1.0->langchain[all])\n",
      "  Obtaining dependency information for googleapis-common-protos>=1.53.0 from https://files.pythonhosted.org/packages/a7/bc/416a1ffeba4dcd072bc10523dac9ed97f2e7fc4b760580e2bdbdc1e2afdd/googleapis_common_protos-1.60.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading googleapis_common_protos-1.60.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from cryptography>=2.5->azure-identity<2.0.0,>=1.12.0->langchain[all]) (1.15.1)\n",
      "Collecting httpcore<0.19.0,>=0.18.0 (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search<4.0.0,>=3.8.3->langchain[all])\n",
      "  Obtaining dependency information for httpcore<0.19.0,>=0.18.0 from https://files.pythonhosted.org/packages/ac/97/724afbb7925339f6214bf1fdb5714d1a462690466832bf8fb3fd497649f1/httpcore-0.18.0-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-0.18.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting brotli (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search<4.0.0,>=3.8.3->langchain[all])\n",
      "  Obtaining dependency information for brotli from https://files.pythonhosted.org/packages/d5/00/40f760cc27007912b327fe15bf6bfd8eaecbe451687f72a8abc587d503b3/Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata\n",
      "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search<4.0.0,>=3.8.3->langchain[all])\n",
      "  Downloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
      "Collecting h2<5,>=3 (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search<4.0.0,>=3.8.3->langchain[all])\n",
      "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib_metadata<7.0,>=6.0->cohere<5,>=4->langchain[all]) (3.16.2)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from numba>=0.51.0->librosa<0.11.0,>=0.10.0.post2->langchain[all]) (0.40.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.18.1->langchain[all]) (0.4.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa<0.11.0,>=0.10.0.post2->langchain[all]) (3.2.0)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow<2.14,>=2.13.0->tensorflow-text<3.0.0,>=2.11.0->langchain[all])\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow<2.14,>=2.13.0->tensorflow-text<3.0.0,>=2.11.0->langchain[all])\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow<2.14,>=2.13.0->tensorflow-text<3.0.0,>=2.11.0->langchain[all])\n",
      "  Obtaining dependency information for flatbuffers>=23.1.21 from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow<2.14,>=2.13.0->tensorflow-text<3.0.0,>=2.11.0->langchain[all])\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text<3.0.0,>=2.11.0->langchain[all]) (0.2.0)\n",
      "Collecting h5py>=2.9.0 (from tensorflow<2.14,>=2.13.0->tensorflow-text<3.0.0,>=2.11.0->langchain[all])\n",
      "  Obtaining dependency information for h5py>=2.9.0 from https://files.pythonhosted.org/packages/0d/7a/e55589e4093cca1934db5e99644c1c2424a9b3aac104b7f6176605a5eeb7/h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow<2.14,>=2.13.0->tensorflow-text<3.0.0,>=2.11.0->langchain[all])\n",
      "  Obtaining dependency information for keras<2.14,>=2.13.1 from https://files.pythonhosted.org/packages/2e/f3/19da7511b45e80216cbbd9467137b2d28919c58ba1ccb971435cb631e470/keras-2.13.1-py3-none-any.whl.metadata\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow<2.14,>=2.13.0->tensorflow-text<3.0.0,>=2.11.0->langchain[all])\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/ea/df/55525e489c43f9dbb6c8ea27d8a567b3dcd18a22f3c45483055f5ca6611d/libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl.metadata\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting numpy<2,>=1 (from langchain[all])\n",
      "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow<2.14,>=2.13.0->tensorflow-text<3.0.0,>=2.11.0->langchain[all])\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.14,>=2.13 (from tensorflow<2.14,>=2.13.0->tensorflow-text<3.0.0,>=2.11.0->langchain[all])\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow<2.14,>=2.13.0->tensorflow-text<3.0.0,>=2.11.0->langchain[all])\n",
      "  Obtaining dependency information for tensorflow-estimator<2.14,>=2.13.0 from https://files.pythonhosted.org/packages/72/5c/c318268d96791c6222ad7df1651bbd1b2409139afeb6f468c0f327177016/tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text<3.0.0,>=2.11.0->langchain[all]) (2.3.0)\n",
      "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting msrest>=0.6.21 (from azure-ai-formrecognizer<4.0.0,>=3.2.1->langchain[all])\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting azure-core<2.0.0,>=1.23.0 (from azure-ai-formrecognizer<4.0.0,>=3.2.1->langchain[all])\n",
      "  Obtaining dependency information for azure-core<2.0.0,>=1.23.0 from https://files.pythonhosted.org/packages/0e/20/2f7a562c6a600b32c64ebe00cc9e4c3099bc42d52aadcafd3a2a8fa0d68a/azure_core-1.29.3-py3-none-any.whl.metadata\n",
      "  Downloading azure_core-1.29.3-py3-none-any.whl.metadata (35 kB)\n",
      "  Obtaining dependency information for azure-core<2.0.0,>=1.23.0 from https://files.pythonhosted.org/packages/78/f5/0e2e1eee5548ef539461183024ccdd0397a920b33fdd092c9af489ab1940/azure_core-1.29.2-py3-none-any.whl.metadata\n",
      "  Downloading azure_core-1.29.2-py3-none-any.whl.metadata (35 kB)\n",
      "  Obtaining dependency information for azure-core<2.0.0,>=1.23.0 from https://files.pythonhosted.org/packages/fb/4e/75fb100cdc22dde79cf10431dba3cbb1b4f77499cff63d767163d1e7511d/azure_core-1.29.1-py3-none-any.whl.metadata\n",
      "  Downloading azure_core-1.29.1-py3-none-any.whl.metadata (35 kB)\n",
      "Collecting typing-extensions>=4.5.0 (from aleph-alpha-client<3.0.0,>=2.15.0->langchain[all])\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow<2.14,>=2.13.0->tensorflow-text<3.0.0,>=2.11.0->langchain[all])\n",
      "  Obtaining dependency information for tensorflow-io-gcs-filesystem>=0.23.1 from https://files.pythonhosted.org/packages/88/99/8b507a009359fd55e411001acb64a1a8a4f81a26cb6e21c3b75c7fda4ae3/tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\n",
      "Collecting pyphen (from textstat<0.8.0,>=0.7.3->langkit<0.1.0,>=0.0.6->langchain[all])\n",
      "  Downloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting types-urllib3 (from types-requests>=2.28.11.6->docarray[hnswlib]<0.33.0,>=0.32.0->langchain[all])\n",
      "  Obtaining dependency information for types-urllib3 from https://files.pythonhosted.org/packages/11/7b/3fc711b2efea5e85a7a0bbfe269ea944aa767bbba5ec52f9ee45d362ccf3/types_urllib3-1.26.25.14-py3-none-any.whl.metadata\n",
      "  Downloading types_urllib3-1.26.25.14-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain[all])\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting pytz-deprecation-shim (from tzlocal<5.0,>=4.0->O365<3.0.0,>=2.0.26->langchain[all])\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting pyproject_hooks (from build->singlestoredb<0.8.0,>=0.7.1->langchain[all])\n",
      "  Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from build->singlestoredb<0.8.0,>=0.7.1->langchain[all]) (2.0.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from docker->pyvespa<0.34.0,>=0.33.0->langchain[all]) (1.6.1)\n",
      "Collecting sgmllib3k (from feedparser->arxiv<2.0,>=1.4->langchain[all])\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: entrypoints in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from numcodecs->deeplake<4.0.0,>=3.6.8->langchain[all]) (0.4)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->deeplake<4.0.0,>=3.6.8->langchain[all]) (1.7.6.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->deeplake<4.0.0,>=3.6.8->langchain[all]) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->deeplake<4.0.0,>=3.6.8->langchain[all]) (0.70.14)\n",
      "Collecting py<2.0.0,>=1.4.26 (from retry->lancedb<0.2,>=0.1->langchain[all])\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2.0.0,>=1.12.0->langchain[all]) (2.21)\n",
      "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search<4.0.0,>=3.8.3->langchain[all])\n",
      "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search<4.0.0,>=3.8.3->langchain[all])\n",
      "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore<0.19.0,>=0.18.0->httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search<4.0.0,>=3.8.3->langchain[all])\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m479.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich==13.4.2->clarifai>=9.1.0->langchain[all])\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text<3.0.0,>=2.11.0->langchain[all])\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text<3.0.0,>=2.11.0->langchain[all])\n",
      "  Obtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/1a/b5/228c1cdcfe138f1a8e01ab1b54284c8b83735476cb22b6ba251656ed13ad/Markdown-3.4.4-py3-none-any.whl.metadata\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text<3.0.0,>=2.11.0->langchain[all])\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/02/52/fb9e51fba47951aabd7a6b25e41d73eae94208ccf62d886168096941a781/tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text<3.0.0,>=2.11.0->langchain[all]) (2.3.6)\n",
      "Requirement already satisfied: tzdata in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pytz-deprecation-shim->tzlocal<5.0,>=4.0->O365<3.0.0,>=2.0.26->langchain[all]) (2023.3)\n",
      "Downloading aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading arxiv-1.4.8-py3-none-any.whl (12 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading atlassian_python_api-3.41.2-py3-none-any.whl (167 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.2/167.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading awadb-0.3.10-cp310-cp310-manylinux1_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading azure_ai_formrecognizer-3.3.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading azure_cognitiveservices_speech-1.32.1-py3-none-manylinux1_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading azure_cosmos-4.5.1-py3-none-any.whl (230 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.6/230.6 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_identity-1.14.0-py3-none-any.whl (160 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.2/160.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading clarifai-9.8.1-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tritonclient-2.34.0-py3-none-manylinux1_x86_64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading clickhouse_connect-0.5.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.7/922.7 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cohere-4.27-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m453.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastavro-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.0-py3-none-any.whl (27 kB)\n",
      "Downloading duckduckgo_search-3.8.5-py3-none-any.whl (18 kB)\n",
      "Downloading elasticsearch-8.9.0-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.5/395.5 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.23.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.4/181.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gptcache-0.1.41-py3-none-any.whl (131 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jq-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (656 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m656.0/656.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading lancedb-0.1.16-py3-none-any.whl (34 kB)\n",
      "Downloading pylance-0.5.10-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langkit-0.0.19-py3-none-any.whl (769 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.1/769.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading whylogs-1.2.6-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.0.40-py3-none-any.whl (39 kB)\n",
      "Downloading lark-1.1.7-py3-none-any.whl (108 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libdeeplake-0.0.60-cp310-cp310-manylinux2010_x86_64.whl (10.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading librosa-0.10.1-py3-none-any.whl (253 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.7/253.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lxml-4.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading marqo-1.3.1-py3-none-any.whl (36 kB)\n",
      "Downloading momento-1.9.2-py3-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.4/134.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nlpcloud-1.1.44-py3-none-any.whl (4.4 kB)\n",
      "Downloading numexpr-2.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (383 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.8/383.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading O365-2.0.28-py3-none-any.whl (164 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.6/164.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openlm-0.0.5-py3-none-any.whl (10 kB)\n",
      "Downloading opensearch_py-2.3.1-py2.py3-none-any.whl (327 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.3/327.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pgvector-0.1.8-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading pinecone_client-2.2.4-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.4/179.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading psycopg2_binary-2.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pymongo-4.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.3/671.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-3.16.1-py3-none-any.whl (276 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.3/276.3 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_arango-7.6.2-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading qdrant_client-1.5.4-py3-none-any.whl (144 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading redis-4.6.0-py3-none-any.whl (241 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.1/241.1 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading singlestoredb-0.7.1-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.8/216.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.21-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tigrisdb-1.0.0b6-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m458.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading weaviate_client-3.24.1-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.0.299-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aioboto3-11.3.0-py3-none-any.whl (32 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading Authlib-1.2.1-py2.py3-none-any.whl (215 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_core-1.29.1-py3-none-any.whl (188 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.28.17-py3-none-any.whl (135 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Downloading clarifai_grpc-9.8.3-py3-none-any.whl (217 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.9/217.9 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.11.1-py3-none-any.whl (120 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.5/120.5 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_httplib2-0.1.1-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading grpcio-1.58.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_tools-1.58.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading humbug-0.3.2-py3-none-any.whl (15 kB)\n",
      "Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading momento_wire_types-0.75.0-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msal-1.24.0-py2.py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.3/91.3 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (530 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m530.8/530.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m771.9/771.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.3.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_hub-0.14.0-py2.py3-none-any.whl (90 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.3/90.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading types_requests-2.31.0.3-py3-none-any.whl (14 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading tzlocal-4.3.1-py3-none-any.whl (20 kB)\n",
      "Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
      "Downloading build-1.0.3-py3-none-any.whl (18 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading docarray-0.32.1-py3-none-any.whl (215 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading more_itertools-10.1.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading semver-3.0.1-py3-none-any.whl (17 kB)\n",
      "Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.31.17-py3-none-any.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_rapidjson-1.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading whylabs_client-0.5.7-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.0/402.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading types_urllib3-1.26.25.14-py3-none-any.whl (15 kB)\n",
      "Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m127.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiobotocore-2.6.0-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: amadeus, deeplake, esprima, google-search-results, neo4j, nomic, sentence-transformers, wikipedia, audioread, future, hnswlib, sqlitedict, stringcase, wget, sgmllib3k\n",
      "  Building wheel for amadeus (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for amadeus: filename=amadeus-9.0.0-py2.py3-none-any.whl size=75046 sha256=84dcfb97f985e767d2d8bf89da1a93ac48ddce1cdc8a387f390370624e78ae3a\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/b0/50/ea/3417d93eee6760a945d7711333d8d42b9f482e84600ef7f711\n",
      "  Building wheel for deeplake (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deeplake: filename=deeplake-3.6.26-py3-none-any.whl size=660903 sha256=e074ab1ae0b6dbbef11cad815e0a1f646eec2be10df42b3ce9715c5cc6978905\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/f9/2e/77/5a105f65959e2e22ef87ef416efc64e4a5e954a84e4b232456\n",
      "  Building wheel for esprima (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for esprima: filename=esprima-4.0.1-py3-none-any.whl size=62239 sha256=acd5898668be51715458ef8915c6d2fd8e1f002b421318ea711ddf1972895c6e\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/7c/ad/8b/afd6e521e6aaea5482b7b4665ff3ce5a92373bd285e7d3a85c\n",
      "  Building wheel for google-search-results (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32002 sha256=c89ae803c37c9f26ec6fba98df283823caf37a800b84234940fc0eb3d1207a6b\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
      "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for neo4j: filename=neo4j-5.12.0-py3-none-any.whl size=263745 sha256=5d3c105335a016eb2feda2286e85b488e8cbb86f91f80c078cce9c67aeba416a\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/6a/ea/49/d6abec5b49a566a80395ebb8e9744352e6512ab15ce0c8f40a\n",
      "  Building wheel for nomic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nomic: filename=nomic-1.1.14-py3-none-any.whl size=33821 sha256=17d433df2d2aaf0cb072295cc10242d39db393363d51f89f580456b234ce04b8\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/4c/dd/9a/57a82068ce36ce73954949a52ebaa1745441728b8b0233421e\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=5667916d0d4ce4022f752583dff68869d23eec1bd8cbb1e294ab57656ad0c105\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=466f010bd4d9dd1a021db502ea5461e939ec5dc2ff974ac722c73926d23e3b93\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for audioread: filename=audioread-3.0.0-py3-none-any.whl size=23706 sha256=81a966c9e3e128adf39de6fa04bf449bd0ce92cf2b819fa86ee573e2ee30d374\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/da/4b/39/c5f6c4ee93b43281dda4dab5ac5f2bdf9d11074d427493cd55\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492022 sha256=59a996f0683697b2f93be7f1a9dd1045d6d5ead9cdf0880ae599e183edbf8f4a\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/5e/a9/47/f118e66afd12240e4662752cc22cefae5d97275623aa8ef57d\n",
      "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp310-cp310-linux_x86_64.whl size=175742 sha256=6fa25ca174f805f255f8a08fa18a95df9d7683321f8584bbc8abe4556450648f\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/8a/ae/ec/235a682e0041fbaeee389843670581ec6c66872db856dfa9a4\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=fb14a5720253c5e0799dc050739339c80b9dfd3d909da4a9d846406c3183d934\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
      "  Building wheel for stringcase (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for stringcase: filename=stringcase-1.2.0-py3-none-any.whl size=3569 sha256=58658566f0260ed33dc46e5de577fa6b41593837056acc38c78fa95e7a942183\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/31/ba/22/1a2d952a9ce8aa86e42fda41e2c87fdaf20e238c88bf8df013\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=c881d634b1f8870f001ef7e9fe7a3ce171aaf8577cab04ba5015781375ff181d\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=88bc780a51e5040ef497b3e2e2a0475118f2007fcb2b695a0d07715682965cd6\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
      "Successfully built amadeus deeplake esprima google-search-results neo4j nomic sentence-transformers wikipedia audioread future hnswlib sqlitedict stringcase wget sgmllib3k\n",
      "Installing collected packages: whylogs-sketching, wget, types-urllib3, tokenizers, stringcase, sqlitedict, sgmllib3k, sentencepiece, safetensors, ratelimiter, mmh3, libclang, geojson, flatbuffers, faiss-cpu, esprima, brotli, azure-common, attr, zstandard, xmltodict, wrapt, wonderwords, validators, uritemplate, typing-extensions, types-requests, tqdm, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, sqlparams, socksio, semver, regex, pytz-deprecation-shim, python-rapidjson, pyproject_hooks, pyphen, pypdf, pyjwt, pyasn1-modules, py, psycopg2-binary, portalocker, packaging, orjson, oauthlib, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, networkx, neo4j, mypy-extensions, multidict, msgpack, more-itertools, mdurl, markdown, lz4, lxml, loguru, lazy-loader, lark, keras, jsonpatch, jsonlines, jq, jaraco.context, isodate, hyperframe, httplib2, html2text, hpack, h11, grpcio, greenlet, googleapis-common-protos, gast, future, frozenlist, feedparser, fastavro, elastic-transport, dnspython, cachetools, backoff, azure-cognitiveservices-speech, azure-ai-vision, awadb, audioread, async-timeout, astunparse, amadeus, aioitertools, aiofiles, absl-py, yarl, wolframalpha, wikipedia, whylabs-client, tzlocal, typing-inspect, tritonclient, tiktoken, textstat, tensorflow-hub, SQLAlchemy, soxr, soundfile, retry, requests-toolbelt, requests-oauthlib, redis, rdflib, pytesseract, pymongo, pydantic, pycares, pinecone-client, pgvector, opt-einsum, opensearch-py, openlm, nvidia-cudnn-cu11, numexpr, numcodecs, nltk, nlpcloud, nebula3-python, momento-wire-types, marshmallow, markdown-it-py, libdeeplake, humbug, huggingface_hub, httpcore, hnswlib, h5py, h2, grpcio-tools, gptcache, google-search-results, google-auth, elasticsearch, deprecated, clickhouse-connect, clarifai-grpc, build, botocore, azure-core, arxiv, aiosignal, whylogs, transformers, torch, tigrisdb, singlestoredb, rich, python-arango, pyowm, pylance, pdfminer-six, O365, msrest, momento, marqo, manifest-ml, langsmith, httpx, google-auth-oauthlib, google-auth-httplib2, google-api-core, dataclasses-json, azure-cosmos, authlib, atlassian-python-api, aiohttp, aiodns, weaviate-client, tensorboard, pyvespa, openai, msal, librosa, langkit, langchain, lancedb, google-api-python-client, docarray, cohere, clarifai, boto3, azure-ai-formrecognizer, aiohttp-retry, aiobotocore, tensorflow, sentence-transformers, qdrant-client, nomic, msal-extensions, duckduckgo-search, aleph-alpha-client, tensorflow-text, pinecone-text, azure-identity, aioboto3, deeplake\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.1\n",
      "    Uninstalling networkx-3.1:\n",
      "      Successfully uninstalled networkx-3.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.0.3\n",
      "    Uninstalling pydantic-2.0.3:\n",
      "      Successfully uninstalled pydantic-2.0.3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.31.41\n",
      "    Uninstalling botocore-1.31.41:\n",
      "      Successfully uninstalled botocore-1.31.41\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1\n",
      "    Uninstalling torch-2.0.1:\n",
      "      Successfully uninstalled torch-2.0.1\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.28.41\n",
      "    Uninstalling boto3-1.28.41:\n",
      "      Successfully uninstalled boto3-1.28.41\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "triton 2.0.0 requires cmake, which is not installed.\n",
      "triton 2.0.0 requires lit, which is not installed.\n",
      "awscli 1.29.41 requires botocore==1.31.41, but you have botocore 1.31.17 which is incompatible.\n",
      "pydantic-core 2.3.0 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed O365-2.0.28 SQLAlchemy-2.0.21 absl-py-2.0.0 aioboto3-11.3.0 aiobotocore-2.6.0 aiodns-3.0.0 aiofiles-23.2.1 aiohttp-3.8.5 aiohttp-retry-2.8.3 aioitertools-0.11.0 aiosignal-1.3.1 aleph-alpha-client-2.17.0 amadeus-9.0.0 arxiv-1.4.8 astunparse-1.6.3 async-timeout-4.0.3 atlassian-python-api-3.41.2 attr-0.3.2 audioread-3.0.0 authlib-1.2.1 awadb-0.3.10 azure-ai-formrecognizer-3.3.0 azure-ai-vision-0.11.1b1 azure-cognitiveservices-speech-1.32.1 azure-common-1.1.28 azure-core-1.29.1 azure-cosmos-4.5.1 azure-identity-1.14.0 backoff-2.2.1 boto3-1.28.17 botocore-1.31.17 brotli-1.1.0 build-1.0.3 cachetools-5.3.1 clarifai-9.8.1 clarifai-grpc-9.8.3 clickhouse-connect-0.5.25 cohere-4.27 dataclasses-json-0.6.0 deeplake-3.6.26 deprecated-1.2.14 dnspython-2.4.2 docarray-0.32.1 duckduckgo-search-3.8.5 elastic-transport-8.4.0 elasticsearch-8.9.0 esprima-4.0.1 faiss-cpu-1.7.4 fastavro-1.8.2 feedparser-6.0.10 flatbuffers-23.5.26 frozenlist-1.4.0 future-0.18.3 gast-0.4.0 geojson-2.5.0 google-api-core-2.11.1 google-api-python-client-2.70.0 google-auth-2.23.0 google-auth-httplib2-0.1.1 google-auth-oauthlib-1.0.0 google-search-results-2.4.2 googleapis-common-protos-1.60.0 gptcache-0.1.41 greenlet-2.0.2 grpcio-1.58.0 grpcio-tools-1.58.0 h11-0.14.0 h2-4.1.0 h5py-3.9.0 hnswlib-0.7.0 hpack-4.0.0 html2text-2020.1.16 httpcore-0.18.0 httplib2-0.22.0 httpx-0.25.0 huggingface_hub-0.17.2 humbug-0.3.2 hyperframe-6.0.1 isodate-0.6.1 jaraco.context-4.3.0 jq-1.6.0 jsonlines-4.0.0 jsonpatch-1.33 keras-2.13.1 lancedb-0.1.16 langchain-0.0.299 langkit-0.0.19 langsmith-0.0.40 lark-1.1.7 lazy-loader-0.3 libclang-16.0.6 libdeeplake-0.0.60 librosa-0.10.1 loguru-0.7.2 lxml-4.9.3 lz4-4.3.2 manifest-ml-0.0.1 markdown-3.4.4 markdown-it-py-3.0.0 marqo-1.3.1 marshmallow-3.20.1 mdurl-0.1.2 mmh3-3.1.0 momento-1.9.2 momento-wire-types-0.75.0 more-itertools-10.1.0 msal-1.24.0 msal-extensions-1.0.0 msgpack-1.0.6 msrest-0.7.1 multidict-6.0.4 mypy-extensions-1.0.0 nebula3-python-3.4.0 neo4j-5.12.0 networkx-2.8.8 nlpcloud-1.1.44 nltk-3.8.1 nomic-1.1.14 numcodecs-0.11.0 numexpr-2.8.6 numpy-1.24.3 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 oauthlib-3.2.2 openai-0.28.0 openlm-0.0.5 opensearch-py-2.3.1 opt-einsum-3.3.0 orjson-3.9.7 packaging-23.1 pdfminer-six-20221105 pgvector-0.1.8 pinecone-client-2.2.4 pinecone-text-0.4.2 portalocker-2.8.2 psycopg2-binary-2.9.7 py-1.11.0 pyasn1-modules-0.3.0 pycares-4.3.0 pydantic-1.10.12 pyjwt-2.8.0 pylance-0.5.10 pymongo-4.5.0 pyowm-3.3.0 pypdf-3.16.1 pyphen-0.14.0 pyproject_hooks-1.0.0 pytesseract-0.3.10 python-arango-7.6.2 python-rapidjson-1.11 pytz-deprecation-shim-0.1.0.post0 pyvespa-0.33.0 qdrant-client-1.5.4 ratelimiter-1.2.0.post0 rdflib-6.3.2 redis-4.6.0 regex-2023.8.8 requests-oauthlib-1.3.1 requests-toolbelt-1.0.0 retry-0.9.2 rich-13.4.2 safetensors-0.3.3 semver-3.0.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 sgmllib3k-1.0.0 singlestoredb-0.7.1 socksio-1.0.0 soundfile-0.12.1 soxr-0.3.6 sqlitedict-2.1.0 sqlparams-5.1.0 stringcase-1.2.0 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-hub-0.14.0 tensorflow-io-gcs-filesystem-0.34.0 tensorflow-text-2.13.0 textstat-0.7.3 tigrisdb-1.0.0b6 tiktoken-0.3.3 tokenizers-0.13.3 torch-1.13.1 tqdm-4.64.1 transformers-4.33.2 tritonclient-2.34.0 types-requests-2.31.0.3 types-urllib3-1.26.25.14 typing-extensions-4.5.0 typing-inspect-0.9.0 tzlocal-4.3.1 uritemplate-4.1.1 validators-0.22.0 weaviate-client-3.24.1 wget-3.2 whylabs-client-0.5.7 whylogs-1.2.6 whylogs-sketching-3.4.1.dev3 wikipedia-1.4.0 wolframalpha-5.0.0 wonderwords-2.2.0 wrapt-1.15.0 xmltodict-0.13.0 yarl-1.9.2 zstandard-0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain[all]\n",
    "#!pip install sagemaker --upgrade\n",
    "#!pip install  boto3\n",
    "#!pip install requests_aws4auth\n",
    "#!pip install opensearch-py\n",
    "#!pip install pydantic==1.10.0\n",
    "#!pip install PyAthena[SQLAlchemy]==1.0.0\n",
    "#!pip install PyAthena[JDBC]==1.0.0\n",
    "#!pip install openai\n",
    "# !pip install sqlalchemy-redshift\n",
    "# !pip install redshift_connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e84906db-5ec4-4270-8c7a-e32f9f8c5460",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /home/ec2-user/.config/pip/pip.conf\n"
     ]
    }
   ],
   "source": [
    "!pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "801dfad3-4698-4a2b-ae72-189ec0c41523",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting pymysql\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e5/30/20467e39523d0cfc2b6227902d3687a16364307260c75e6a1cb4422b0c62/PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m145.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b216f11-a2b5-4f0b-b4de-060a1a64076a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## initial sagemaker env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19f05414-d44b-464e-a0c7-46c317378ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::687912291502:role/service-role/AmazonSageMaker-ExecutionRole-20211013T113123\n",
      "sagemaker bucket: sagemaker-us-west-2-687912291502\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import boto3\n",
    "import json\n",
    "from typing import Dict\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "sm_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3aed78-e14b-4d30-93d3-2871d6603bd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## intial lanchain lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aae9f94-a8df-49b5-b22b-f89e8d756b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from langchain import PromptTemplate, SagemakerEndpoint\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.llms.sagemaker_endpoint import ContentHandlerBase\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.memory import ConversationBufferWindowMemory,ConversationBufferMemory\n",
    "from langchain import LLMChain\n",
    "from typing import Dict\n",
    "\n",
    "# set environment OPENAI_API_KEY\n",
    "# os.environ[\"OPENAI_API_KEY\"] = ...\n",
    "#from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "aos_endpoint=\"vpc-llm-rag-aos-seg3mzhpp76ncpxezdqtcsoiga.us-west-2.es.amazonaws.com\"\n",
    "region='us-west-2'\n",
    "# replace to your username and passsword\n",
    "username=\"admin\"\n",
    "passwd=\"\"\n",
    "index_name=\"qa_index\"\n",
    "size=10\n",
    "\n",
    "## for chatglm\n",
    "class TextGenContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        #input_str = json.dumps({prompt: prompt, **model_kwargs})\n",
    "        input_str = json.dumps({\n",
    "                \"ask\": prompt,\n",
    "                \"parameters\": model_kwargs\n",
    "            })\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[\"answer\"]\n",
    "\n",
    "### for vicuna/llama\n",
    "class TextGenContentHandler2(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\n",
    "                \"inputs\": prompt,\n",
    "                \"parameters\": model_kwargs\n",
    "            })\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        #print(response_json)\n",
    "        #sql_result=response_json[\"outputs\"].split(\"```sql\")[-1].split(\"```\")[0].split(\";\")[0].strip().replace(\"\\\\n\",\" \") + \";\"\n",
    "        sql_result=response_json[\"outputs\"]\n",
    "        return sql_result\n",
    "\n",
    "\n",
    "content_hander2=TextGenContentHandler2()\n",
    "\n",
    "parameters = {\n",
    "  #\"early_stopping\": True,\n",
    "  #\"length_penalty\": 2.0,\n",
    "  \"max_new_tokens\": 300,\n",
    "  #\"temperature\": 0.6,\n",
    "  #\"max_tokens\": 300,\n",
    "  #\"no_repeat_ngram_size\": 2,\n",
    "}\n",
    "sm_llm=SagemakerEndpoint(\n",
    "        #endpoint_name=\"chatglm-inference-0524-2023-06-01-07-11-27-379\",\n",
    "        endpoint_name=\"sqlcoder-2023-09-23-00-54-24-198-endpoint\",\n",
    "        #endpoint_name=\"codellame-2023-09-22-09-25-02-063-endpoint\",\n",
    "        region_name=\"us-west-2\", \n",
    "        model_kwargs=parameters,\n",
    "        content_handler=content_hander2,\n",
    "        #endpoint_kwargs={'CustomAttributes':'accept_eula=true'}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa302e0a-b8ed-4fa0-934e-ab4ff0740316",
   "metadata": {
    "tags": []
   },
   "source": [
    "## major chain pipeline ################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa19652-7785-42f6-a74f-bc31ff4ca28a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 直接使用 langchain SQLDatabaseChain \n",
    "定制SqlDataBase对接其他数据源(e.g StarRocks)   \n",
    "SqlDatabaseChain使用sagemaker endpoint llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "634c6070-af8c-40b7-b655-e6eb37eff456",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT count(*) FROM ads_bi_quality_monitor_shipping_detail WHERE temp_right_tag = '合格' and DATE_SUB(CURDATE(), INTERVAL 1 MONTH) <= shipping_create_time;\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "sql_cmd=\"\"\"\n",
    "You are a MySQL expert. Given an input question, first create a syntactically correct MySQL query to run, then look at the results of the query and return the answer to the input question.\n",
    "Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per MySQL. You can order the results to return the most informative data in the database.\n",
    "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use CURDATE() function to get the current date, if the question involves \"today\".\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: Question here\n",
    "SQLQuery: SQL Query to run\n",
    "SQLResult: Result of the SQLQuery\n",
    "Answer: Final answer here\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "CREATE TABLE ads_bi_quality_monitor_shipping_detail (\n",
    "\tshipping_order_code VARCHAR(100) COMMENT '派车单编码', \n",
    "\tlicense_plate VARCHAR(100) COMMENT '车牌号', \n",
    "\ttruck_type VARCHAR(50) COMMENT '车辆类型', \n",
    "\ttenant_id VARCHAR(100) COMMENT '租户编码', \n",
    "\ttenant_name VARCHAR(200) COMMENT '租户名称', \n",
    "\tfather_company_code VARCHAR(100) COMMENT '分子公司编码', \n",
    "\tfather_company_name VARCHAR(200) COMMENT '分子公司名称', \n",
    "\tfather_company_short_name VARCHAR(200) COMMENT '分子公司简称', \n",
    "\tstart_transport_time VARCHAR(50) COMMENT '运输出发时间', \n",
    "\tsigning_time VARCHAR(50) COMMENT '派车单签收时间', \n",
    "\tplan_start_time VARCHAR(50) COMMENT '派车单计划取货时间', \n",
    "\tplan_end_time VARCHAR(50) COMMENT '派车单计划送达时间', \n",
    "\tfrist_fence_time VARCHAR(50) COMMENT '第一次碰撞装货地电子围栏时间', \n",
    "\tleave_load_station_2km_time VARCHAR(50) COMMENT '离开最后一个装货地电子围栏2km的时间', \n",
    "\tfrist_arrive_unload_time VARCHAR(50) COMMENT '首次到达卸货点电子围栏时间', \n",
    "\ttransport_type VARCHAR(10) COMMENT '运输类型(干线/城配)', \n",
    "\tplan_mileage VARCHAR(50) COMMENT '计划里程', \n",
    "\tdriver_accept_time VARCHAR(50) COMMENT '司机接单时间', \n",
    "\tdriver_name VARCHAR(50) COMMENT '司机姓名', \n",
    "\tdriver_phone VARCHAR(50) COMMENT '司机电话', \n",
    "\tdriver_type VARCHAR(10) COMMENT '司机类型', \n",
    "\ttransport_tenant_id VARCHAR(100) COMMENT '运力承运商id', \n",
    "\ttransport_tenant_name VARCHAR(200) COMMENT '运力承运商名称', \n",
    "\twarm_area VARCHAR(50) COMMENT '温区信息', \n",
    "\twaybill_count INTEGER COMMENT '运单数量', \n",
    "\tgps_device_list VARCHAR(100) COMMENT 'gps设备', \n",
    "\tgps_report_dot_num INTEGER COMMENT 'gps上报点数', \n",
    "\ttemp_substandard_min DECIMAL(20, 8) COMMENT '温度不达标时长(分钟)', \n",
    "\ttemp_substandard_min_n12 DECIMAL(20, 8) COMMENT '温度不达标时长(分钟)_-12', \n",
    "\ttemp_substandard_min_n16 DECIMAL(20, 8) COMMENT '温度不达标时长(分钟)_-16', \n",
    "\tshipping_order_transport_min DECIMAL(20, 8) COMMENT '派车单运输总时长(分钟)', \n",
    "\tshipping_order_temp_standard_rate DECIMAL(20, 8) COMMENT '派车单温度达标率', \n",
    "\tshipping_order_temp_standard_rate_n12 DECIMAL(20, 8) COMMENT '派车单温度达标率_-12', \n",
    "\tshipping_order_temp_standard_rate_n16 DECIMAL(20, 8) COMMENT '派车单温度达标率_-16', \n",
    "\tdep_fence_match_num INTEGER COMMENT '出发地电子围栏匹配数量', \n",
    "\tdep_total_num INTEGER COMMENT '出发地总数量', \n",
    "\tdep_fence_match_rate DECIMAL(20, 8) COMMENT '出发地电子围栏匹配率', \n",
    "\tdes_fence_match_num INTEGER COMMENT '目的地电子围栏匹配数量', \n",
    "\tdes_total_num INTEGER COMMENT '目的地总数量', \n",
    "\tdes_fence_match_rate DECIMAL(20, 8) COMMENT '目的地电子围栏匹配率', \n",
    "\texception_shipping_order_type VARCHAR(10) COMMENT '异常派车单情况,0-非异常', \n",
    "\tsettlement_tenant_id VARCHAR(100) COMMENT '结算主体租户id', \n",
    "\tsettlement_tenant_name VARCHAR(100) COMMENT '结算主体租户名称', \n",
    "\ttruck_ownership VARCHAR(100) COMMENT '车辆所有权(自有/外请/临时)', \n",
    "\tload_finish_time VARCHAR(50) COMMENT '派车单点击装货完成时间', \n",
    "\tlast_leave_unload_time VARCHAR(50) COMMENT '最后离开卸货点时间', \n",
    "\ttemp_right_tag VARCHAR(20) COMMENT '温度是否合格(合格/不合格/不参与评估)', \n",
    "\twarm_area_type VARCHAR(20) COMMENT '温区类型。常温/冷链/自定义区间', \n",
    "\tsource_dt VARCHAR(20) COMMENT '派车单来源的增量表dt', \n",
    "\tcur_shipping_odr_cust TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci COMMENT '当前派车单对应的客户', \n",
    "\tis_app_operation VARCHAR(10) COMMENT '是否APP操作卡控', \n",
    "\tleave_load_station_time_app VARCHAR(50) COMMENT '离开第一个装货地时间_app', \n",
    "\tfrist_arrive_unload_time_app VARCHAR(50) COMMENT '到达第一个卸货点时间_app', \n",
    "\tlast_arrive_unload_time_app VARCHAR(50) COMMENT '到达最后一个卸货点时间_app', \n",
    "\ttemp_calc_start_time VARCHAR(50) COMMENT '温度计算开始时间', \n",
    "\ttemp_calc_end_time VARCHAR(50) COMMENT '温度计算结束时间', \n",
    "\texception_shipping_order_type_desc VARCHAR(100) COMMENT '异常派车单情况描述', \n",
    "\troot_shipping_odr_cust TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci COMMENT '根派车单对应的客户', \n",
    "\tis_use_custom_temp_range VARCHAR(10) COMMENT '是否使用自定义温度范围', \n",
    "\ttemp_eval_lowest INTEGER COMMENT '温度考核最低值', \n",
    "\ttemp_eval_highest INTEGER COMMENT '温度考核最高值', \n",
    "\tis_gps_cover VARCHAR(10) COMMENT 'GPS是否覆盖', \n",
    "\tshipping_create_time VARCHAR(50) COMMENT '派车单创建时间', \n",
    "\tgps_device_list_plan VARCHAR(100) COMMENT 'GPS设备_预估', \n",
    "\tis_gps_cover_plan VARCHAR(10) COMMENT 'GPS是否覆盖_预估', \n",
    "\tfirst_station_is_on_time VARCHAR(10) COMMENT '首店是否准时', \n",
    "\tis_many_warm VARCHAR(10) COMMENT '是否多温区', \n",
    "\tmany_temp_standard_rate DECIMAL(20, 8) COMMENT '多温区温度达标率', \n",
    "\tlc_standard_ratio DECIMAL(20, 8) COMMENT '冷藏温度达标率', \n",
    "\tld_standard_ratio DECIMAL(20, 8) COMMENT '冷冻温度达标率', \n",
    "\tprobe_warm_list TEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci COMMENT '探头温区'\n",
    ")ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='BI看板_品质监控_派车单明细'\n",
    "\n",
    "Question: 最近一个月温度合格的派车单数量\n",
    "SQLQuery: SELECT count(*) FROM ads_bi_quality_monitor_shipping_detail WHERE temp_right_tag = '合格' and DATE_SUB(CURDATE(), INTERVAL 1 MONTH) <= shipping_create_time;\n",
    "\"\"\"\n",
    "pattern = r\"SQLQuery: (.*?)\\n\"\n",
    "matches = re.findall(pattern, sql_cmd)\n",
    "match = matches[1]\n",
    "sql_cmd = match\n",
    "sql_cmd=sql_cmd.replace(\"SQLQuery:\",\"\")\n",
    "sql_cmd=sql_cmd.replace(\"SQLResult\",\"\")\n",
    "sql_cmd=sql_cmd.replace(\"\\\\\",\"\")\n",
    "print(sql_cmd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "781f2be7-0a3e-4eac-a55b-00b182762326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"SQLAlchemy wrapper around a database.\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import warnings\n",
    "from typing import Any, Iterable, List, Optional\n",
    "import sqlalchemy\n",
    "import re\n",
    "from langchain.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain.base_language import BaseLanguageModel\n",
    "from langchain.callbacks.manager import CallbackManagerForChainRun\n",
    "from sqlalchemy import MetaData, Table, create_engine, inspect, select, text\n",
    "from sqlalchemy.engine import Engine\n",
    "from sqlalchemy.exc import ProgrammingError, SQLAlchemyError\n",
    "from sqlalchemy.schema import CreateTable\n",
    "\n",
    "\n",
    "\n",
    "class CustomerizedSQLDatabase(SQLDatabase):\n",
    "    \n",
    "    def get_table_info(self, table_names: Optional[List[str]] = None) -> str:\n",
    "        \"\"\"Get information about specified tables.\n",
    "\n",
    "        Follows best practices as specified in: Rajkumar et al, 2022\n",
    "        (https://arxiv.org/abs/2204.00498)\n",
    "\n",
    "        If `sample_rows_in_table_info`, the specified number of sample rows will be\n",
    "        appended to each table description. This can increase performance as\n",
    "        demonstrated in the paper.\n",
    "        \"\"\"\n",
    "        all_table_names = self.get_usable_table_names()\n",
    "        if table_names is not None:\n",
    "            missing_tables = set(table_names).difference(all_table_names)\n",
    "            if missing_tables:\n",
    "                raise ValueError(f\"table_names {missing_tables} not found in database\")\n",
    "            all_table_names = table_names\n",
    "\n",
    "        meta_tables = [\n",
    "            tbl\n",
    "            for tbl in self._metadata.sorted_tables\n",
    "            if tbl.name in set(all_table_names)\n",
    "            and not (self.dialect == \"sqlite\" and tbl.name.startswith(\"sqlite_\"))\n",
    "        ]\n",
    "\n",
    "        tables = []\n",
    "        for table in meta_tables:\n",
    "            if self._custom_table_info and table.name in self._custom_table_info:\n",
    "                tables.append(self._custom_table_info[table.name])\n",
    "                continue\n",
    "\n",
    "            # add create table command\n",
    "            create_table = str(CreateTable(table).compile(self._engine))\n",
    "            table_info = f\"{create_table.rstrip()}\"\n",
    "            has_extra_info = (\n",
    "                self._indexes_in_table_info or self._sample_rows_in_table_info\n",
    "            )\n",
    "            if has_extra_info:\n",
    "                table_info += \"\\n\\n/*\"\n",
    "            if self._indexes_in_table_info:\n",
    "                table_info += f\"\\n{self._get_table_indexes(table)}\\n\"\n",
    "            if self._sample_rows_in_table_info:\n",
    "                table_info += f\"\\n{self._get_sample_rows(table)}\\n\"\n",
    "            if has_extra_info:\n",
    "                table_info += \"*/\"\n",
    "            tables.append(table_info)\n",
    "        final_str = \"\\n\\n\".join(tables)\n",
    "        return final_str\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CustomerizedSQLDatabaseChain(SQLDatabaseChain):\n",
    "    \n",
    "    def _call(\n",
    "        self,\n",
    "        inputs: Dict[str, Any],\n",
    "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        _run_manager = run_manager or CallbackManagerForChainRun.get_noop_manager()\n",
    "        input_text = f\"{inputs[self.input_key]}\\nSQLQuery:\"\n",
    "        _run_manager.on_text(input_text, verbose=self.verbose)\n",
    "        # If not present, then defaults to None which is all tables.\n",
    "        table_names_to_use = inputs.get(\"table_names_to_use\")\n",
    "        table_info = self.database.get_table_info(table_names=table_names_to_use)\n",
    "        llm_inputs = {\n",
    "            \"input\": input_text,\n",
    "            \"top_k\": str(self.top_k),\n",
    "            \"dialect\": self.database.dialect,\n",
    "            \"table_info\": table_info,\n",
    "            #\"stop\": [\"\\nSQLResult:\"],\n",
    "        }\n",
    "        intermediate_steps: List = []\n",
    "        try:\n",
    "            intermediate_steps.append(llm_inputs)  # input: sql generation\n",
    "            sql_cmd = self.llm_chain.predict(\n",
    "                callbacks=_run_manager.get_child(),\n",
    "                **llm_inputs,\n",
    "            ).strip()\n",
    "            #print(\"orginal sql_cmd==\"+sql_cmd)\n",
    "            if self.return_sql:\n",
    "                return {self.output_key: sql_cmd}\n",
    "            if not self.use_query_checker:\n",
    "                _run_manager.on_text(sql_cmd, color=\"green\", verbose=self.verbose)\n",
    "                intermediate_steps.append(\n",
    "                    sql_cmd\n",
    "                )  # output: sql generation (no checker)\n",
    "                #########定制sqlcoder 模型输出##############\n",
    "                pattern = r\"SQLQuery: (.*?)\\n\"\n",
    "                matches = re.findall(pattern, sql_cmd)\n",
    "                match = matches[1]\n",
    "                sql_cmd = match\n",
    "                #print(\"query sql==\"+sql_cmd) \n",
    "                \n",
    "                intermediate_steps.append({\"sql_cmd\": sql_cmd})  # input: sql exec\n",
    "                result = self.database.run(sql_cmd)\n",
    "                intermediate_steps.append(str(result))  # output: sql exec\n",
    "            else:\n",
    "                query_checker_prompt = self.query_checker_prompt or PromptTemplate(\n",
    "                    template=QUERY_CHECKER, input_variables=[\"query\", \"dialect\"]\n",
    "                )\n",
    "                query_checker_chain = LLMChain(\n",
    "                    llm=self.llm_chain.llm, prompt=query_checker_prompt\n",
    "                )\n",
    "                query_checker_inputs = {\n",
    "                    \"query\": sql_cmd,\n",
    "                    \"dialect\": self.database.dialect,\n",
    "                }\n",
    "                checked_sql_command: str = query_checker_chain.predict(\n",
    "                    callbacks=_run_manager.get_child(), **query_checker_inputs\n",
    "                ).strip()\n",
    "                intermediate_steps.append(\n",
    "                    checked_sql_command\n",
    "                )  # output: sql generation (checker)\n",
    "                _run_manager.on_text(\n",
    "                    checked_sql_command, color=\"green\", verbose=self.verbose\n",
    "                )\n",
    "                intermediate_steps.append(\n",
    "                    {\"sql_cmd\": checked_sql_command}\n",
    "                )  # input: sql exec\n",
    "                result = self.database.run(checked_sql_command)\n",
    "                intermediate_steps.append(str(result))  # output: sql exec\n",
    "                sql_cmd = checked_sql_command\n",
    "\n",
    "            _run_manager.on_text(\"\\nSQLResult: \", verbose=self.verbose)\n",
    "            _run_manager.on_text(result, color=\"yellow\", verbose=self.verbose)\n",
    "            # If return direct, we just set the final result equal to\n",
    "            # the result of the sql query result, otherwise try to get a human readable\n",
    "            # final answer\n",
    "            if self.return_direct:\n",
    "                final_result = result\n",
    "            else:\n",
    "                _run_manager.on_text(\"\\nAnswer:\", verbose=self.verbose)\n",
    "                input_text += f\"{sql_cmd}\\nSQLResult: {result}\\nAnswer:\"\n",
    "                llm_inputs[\"input\"] = input_text\n",
    "                intermediate_steps.append(llm_inputs)  # input: final answer\n",
    "                final_result = self.llm_chain.predict(\n",
    "                    callbacks=_run_manager.get_child(),\n",
    "                    **llm_inputs,\n",
    "                ).strip()\n",
    "                intermediate_steps.append(final_result)  # output: final answer\n",
    "                _run_manager.on_text(final_result, color=\"green\", verbose=self.verbose)\n",
    "            chain_result: Dict[str, Any] = {self.output_key: final_result}\n",
    "            if self.return_intermediate_steps:\n",
    "                chain_result[INTERMEDIATE_STEPS_KEY] = intermediate_steps\n",
    "            return chain_result\n",
    "        except Exception as exc:\n",
    "            # Append intermediate steps to exception, to aid in logging and later\n",
    "            # improvement of few shot prompt seeds\n",
    "            exc.intermediate_steps = intermediate_steps  # type: ignore\n",
    "            raise exc\n",
    "    \n",
    "    \n",
    "    def _call_new(\n",
    "        self,\n",
    "        inputs: Dict[str, Any],\n",
    "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        _run_manager = run_manager or CallbackManagerForChainRun.get_noop_manager()\n",
    "        input_text = f\"{inputs[self.input_key]}\\nSQLQuery:\"\n",
    "        _run_manager.on_text(input_text, verbose=self.verbose)\n",
    "        # If not present, then defaults to None which is all tables.\n",
    "        table_names_to_use = inputs.get(\"table_names_to_use\")\n",
    "        if table_names_to_use is None:\n",
    "            table_names_to_use = self.database._include_tables\n",
    "        table_info = self.database.get_table_info(table_names=list(table_names_to_use))\n",
    "        llm_inputs = {\n",
    "            \"input\": input_text,\n",
    "            \"top_k\": str(self.top_k),\n",
    "            \"dialect\": self.database.dialect,\n",
    "            \"table_info\": table_info,\n",
    "            #\"stop\": [\"\\nSQLResult:\"],\n",
    "        }\n",
    "        intermediate_steps: List = []\n",
    "        try:\n",
    "            intermediate_steps.append(llm_inputs)  # input: sql generation\n",
    "            sql_cmd = self.llm_chain.predict(\n",
    "                callbacks=_run_manager.get_child(),\n",
    "                **llm_inputs,\n",
    "            ).strip()\n",
    "            if not self.use_query_checker:\n",
    "                _run_manager.on_text(sql_cmd, color=\"green\", verbose=self.verbose)\n",
    "                intermediate_steps.append(\n",
    "                    sql_cmd\n",
    "                )  # output: sql generation (no checker)\n",
    "                intermediate_steps.append({\"sql_cmd\": sql_cmd})  # input: sql exec\n",
    "                ###定制 解析chatglm的输出sql，尝试抽取原始'''内的sql#######\n",
    "                pattern = r\"```([^.]*)```\"\n",
    "                matches = re.findall(pattern, sql_cmd)\n",
    "                for match in matches:\n",
    "                   sql_cmd = match\n",
    "                   sql_cmd=sql_cmd.replace(\"```\",\"\")\n",
    "                   sql_cmd=sql_cmd.replace(\"sql\",\"\")\n",
    "                #########################################################\n",
    "                \n",
    "                ###定制 解析vicuna的输出sql，尝试抽取原始SQLQuery:和Answer: 内的sql#######\n",
    "                #pattern = r\"SQLQuery: (.*?)\\nAnswer\"\n",
    "                #matches = re.findall(pattern, sql_cmd)\n",
    "                #match = matches[0]\n",
    "                #sql_cmd = match\n",
    "                #sql_cmd=sql_cmd.replace(\"SQLQuery:\",\"\")\n",
    "                #sql_cmd=sql_cmd.replace(\"Answer\",\"\")\n",
    "                #sql_cmd=sql_cmd.replace(\"\\\\\",\"\")\n",
    "                #print(sql_cmd) \n",
    "                #########################################################\n",
    "                \n",
    "                \n",
    "                 ###定制 解析bloomz的输出sql，尝试抽取原始SQLQuery:和SQLResult: 内的sql#######\n",
    "                pattern = r\"SQLQuery: (.*?)\\nSQLResult\"\n",
    "                print(\"sql_cmd original==\"+sql_cmd)\n",
    "                matches = re.findall(pattern, sql_cmd)\n",
    "                match = matches[1]\n",
    "                sql_cmd = match\n",
    "                sql_cmd=sql_cmd.replace(\"SQLQuery:\",\"\")\n",
    "                sql_cmd=sql_cmd.replace(\"SQLResult\",\"\")\n",
    "                sql_cmd=sql_cmd.replace(\"\\\\\",\"\")\n",
    "                print(sql_cmd) \n",
    "                #########################################################\n",
    "                \n",
    "                result = self.database.run(sql_cmd)\n",
    "                intermediate_steps.append(str(result))  # output: sql exec\n",
    "            else:\n",
    "                query_checker_prompt = self.query_checker_prompt or PromptTemplate(\n",
    "                    template=QUERY_CHECKER, input_variables=[\"query\", \"dialect\"]\n",
    "                )\n",
    "                query_checker_chain = LLMChain(\n",
    "                    llm=self.llm_chain.llm, prompt=query_checker_prompt\n",
    "                )\n",
    "                print(\"here2===\"+sql_cmd)\n",
    "                query_checker_inputs = {\n",
    "                    \"query\": sql_cmd,\n",
    "                    \"dialect\": self.database.dialect,\n",
    "                }\n",
    "                checked_sql_command: str = query_checker_chain.predict(\n",
    "                    callbacks=_run_manager.get_child(), **query_checker_inputs\n",
    "                ).strip()\n",
    "                intermediate_steps.append(\n",
    "                    checked_sql_command\n",
    "                )  # output: sql generation (checker)\n",
    "                _run_manager.on_text(\n",
    "                    checked_sql_command, color=\"green\", verbose=self.verbose\n",
    "                )\n",
    "                intermediate_steps.append(\n",
    "                    {\"sql_cmd\": checked_sql_command}\n",
    "                )  # input: sql exec\n",
    "                \n",
    "                result = self.database.run(checked_sql_command)\n",
    "                intermediate_steps.append(str(result))  # output: sql exec\n",
    "                sql_cmd = checked_sql_command\n",
    "\n",
    "            _run_manager.on_text(\"\\nSQLResult: \", verbose=self.verbose)\n",
    "            _run_manager.on_text(result, color=\"yellow\", verbose=self.verbose)\n",
    "            # If return direct, we just set the final result equal to\n",
    "            # the result of the sql query result, otherwise try to get a human readable\n",
    "            # final answer\n",
    "\n",
    "            if self.return_direct:\n",
    "                final_result = result\n",
    "            else:\n",
    "                print(\"here8888===\")\n",
    "                print(llm_inputs)\n",
    "                _run_manager.on_text(\"\\nAnswer:\", verbose=self.verbose)\n",
    "                input_text += f\"{sql_cmd}\\nSQLResult: {result}\\nAnswer:\"\n",
    "                llm_inputs[\"input\"] = input_text\n",
    "                intermediate_steps.append(llm_inputs)  # input: final answer\n",
    "                final_result = self.llm_chain.predict(\n",
    "                    callbacks=_run_manager.get_child(),\n",
    "                    **llm_inputs,\n",
    "                ).strip()\n",
    "                intermediate_steps.append(final_result)  # output: final answer\n",
    "                _run_manager.on_text(final_result, color=\"green\", verbose=self.verbose)\n",
    "            chain_result: Dict[str, Any] = {self.output_key: final_result}\n",
    "            if self.return_intermediate_steps:\n",
    "                chain_result[INTERMEDIATE_STEPS_KEY] = intermediate_steps\n",
    "            return chain_result\n",
    "        except Exception as exc:\n",
    "            # Append intermediate steps to exception, to aid in logging and later\n",
    "            # improvement of few shot prompt seeds\n",
    "            exc.intermediate_steps = intermediate_steps  # type: ignore\n",
    "            raise exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d21dbaa-d328-4ae2-a776-98e089667539",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-west-2\n",
      "  Using profile: default\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "def get_bedrock_client(\n",
    "    assumed_role: Optional[str] = None,\n",
    "    region: Optional[str] = None,\n",
    "    runtime: Optional[bool] = True,\n",
    "):\n",
    "  \n",
    "    if region is None:\n",
    "        target_region = os.environ.get(\"AWS_REGION\", os.environ.get(\"AWS_DEFAULT_REGION\"))\n",
    "    else:\n",
    "        target_region = region\n",
    "\n",
    "    print(f\"Create new client\\n  Using region: {target_region}\")\n",
    "    session_kwargs = {\"region_name\": target_region}\n",
    "    client_kwargs = {**session_kwargs}\n",
    "\n",
    "    profile_name = os.environ.get(\"AWS_PROFILE\")\n",
    "    if profile_name:\n",
    "        print(f\"  Using profile: {profile_name}\")\n",
    "        session_kwargs[\"profile_name\"] = profile_name\n",
    "\n",
    "    retry_config = Config(\n",
    "        region_name=target_region,\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "    session = boto3.Session(**session_kwargs)\n",
    "\n",
    "    if assumed_role:\n",
    "        print(f\"  Using role: {assumed_role}\", end='')\n",
    "        sts = session.client(\"sts\")\n",
    "        response = sts.assume_role(\n",
    "            RoleArn=str(assumed_role),\n",
    "            RoleSessionName=\"langchain-llm-1\"\n",
    "        )\n",
    "        print(\" ... successful!\")\n",
    "        client_kwargs[\"aws_access_key_id\"] = response[\"Credentials\"][\"AccessKeyId\"]\n",
    "        client_kwargs[\"aws_secret_access_key\"] = response[\"Credentials\"][\"SecretAccessKey\"]\n",
    "        client_kwargs[\"aws_session_token\"] = response[\"Credentials\"][\"SessionToken\"]\n",
    "        \n",
    "\n",
    "    if runtime:\n",
    "        service_name='bedrock-runtime'\n",
    "    else:\n",
    "        service_name='bedrock'\n",
    "\n",
    "    client_kwargs[\"aws_access_key_id\"] = os.environ.get(\"AWS_ACCESS_KEY_ID\",\"\")\n",
    "    client_kwargs[\"aws_secret_access_key\"] = os.environ.get(\"AWS_SECRET_ACCESS_KEY\",\"\")\n",
    "    \n",
    "    bedrock_client = session.client(\n",
    "        service_name=service_name,\n",
    "        config=retry_config,\n",
    "        **client_kwargs\n",
    "    )\n",
    "\n",
    "    print(\"boto3 Bedrock client successfully created!\")\n",
    "    print(bedrock_client._endpoint)\n",
    "    return bedrock_client\n",
    "\n",
    "\n",
    "\n",
    "## for aksk bedrock\n",
    "def get_bedrock_aksk(secret_name='chatbot_bedrock', region_name = \"us-west-2\"):\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        # For a list of exceptions thrown, see\n",
    "        # https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "        raise e\n",
    "\n",
    "    # Decrypts secret using the associated KMS key.\n",
    "    secret = json.loads(get_secret_value_response['SecretString'])\n",
    "    return secret['BEDROCK_ACCESS_KEY'],secret['BEDROCK_SECRET_KEY']\n",
    "\n",
    "ACCESS_KEY, SECRET_KEY=get_bedrock_aksk()\n",
    "\n",
    "###aksk intial client#######\n",
    "#boto3_bedrock = boto3.client(\n",
    "#    service_name=\"bedrock\",\n",
    "#    region_name=\"us-west-2\",\n",
    "#    endpoint_url=\"https://bedrock.us-west-2.amazonaws.com\",\n",
    "#    aws_access_key_id=\"\",\n",
    "#    aws_secret_access_key=\"*******\"\n",
    "#)\n",
    "\n",
    "#role based initial client#######\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\"  # E.g. \"us-east-1\"\n",
    "os.environ[\"AWS_PROFILE\"] = \"default\"\n",
    "#os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"arn:aws:iam::687912291502:role/service-role/AmazonSageMaker-ExecutionRole-20211013T113123\"  # E.g. \"arn:aws:...\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]=ACCESS_KEY\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]=SECRET_KEY\n",
    "\n",
    "\n",
    "#新boto3 sdk只能session方式初始化bedrock\n",
    "boto3_bedrock = get_bedrock_client(\n",
    "    #assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")\n",
    "\n",
    "parameters_bedrock = {\n",
    "    \"max_tokens_to_sample\": 2048,\n",
    "    #\"temperature\": 0.5,\n",
    "    \"temperature\": 0,\n",
    "    #\"top_k\": 250,\n",
    "    #\"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "}\n",
    "\n",
    "class BedrockModelWrapper(Bedrock):\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        prompt = \"Human: \\n\" + prompt + \"\\nAssistant:\"   ## Satisfy Bedrock-Claude prompt requirements\n",
    "        return super()._call(prompt, stop, run_manager, **kwargs)\n",
    "\n",
    "bedrock_llm = Bedrock(model_id=\"anthropic.claude-v2\", \n",
    "                      client=boto3_bedrock, \n",
    "                      model_kwargs=parameters_bedrock)    \n",
    "bedrock_llm_additional = BedrockModelWrapper(model_id=\"anthropic.claude-v2\", \n",
    "                                          client=boto3_bedrock, \n",
    "                                          model_kwargs=parameters_bedrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc28c0b2-3169-4d67-a083-041d31b507f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load default session, using empty session: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /sessions?name=default (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa9ead51000>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "Failed to persist run: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /chain-runs (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa9e9069cf0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"SQL查询语句:\\n\\n```sql\\nSELECT COUNT(DISTINCT license_plate) AS chengdu_truck_cnt\\nFROM dws_truck_portrait_index_sum_da\\nWHERE city = '成都市'\\n```\\n\\nSQL执行结果:\\n\\n```\\n+-----------------+\\n| chengdu_truck_cnt| \\n+-----------------+\\n|            12345|\\n+-----------------+\\n```\\n\\n答:成都市的车辆资源累计有12345辆。\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## langchain agent demo test##########\n",
    "from langchain.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.chains import create_sql_query_chain\n",
    "import json\n",
    "import os\n",
    "\n",
    "os.environ[\"PGPASSWORD\"] = \"*******\"\n",
    "os.environ[\"LANGCHAIN_HANDLER\"] = \"langchain\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-3lTxHcynfeJ4*******lbkFJz4k968DnZNADqgT583TF\"\n",
    "conn_str = \"awsathena+rest://{aws_access_key_id}:{aws_secret_access_key}@athena.{region_name}.amazonaws.com:443/\"\\\n",
    "           \"{schema_name}?s3_staging_dir={s3_staging_dir}\"\n",
    "conn_str = conn_str.format(\n",
    "    aws_access_key_id=\"**********\",\n",
    "    aws_secret_access_key=\"***********\",\n",
    "    region_name=\"cn-northwest-1\",\n",
    "    schema_name=\"specturmdb\",\n",
    "    s3_staging_dir=\"s3://tangqy-athenaoutput-us-west-2\")\n",
    "\n",
    "db = SQLDatabase.from_uri(\n",
    "    #conn_str,\n",
    "    #\"redshift+redshift_connector://admin@redshift-cluster-1.cp1kgq7oikv3.ap-southeast-1.redshift.amazonaws.com:5439/dev\",\n",
    "    \"mysql+pymysql://admin:admin12345678@database-us-west-2-demo.cluster-c1qvx9wzmmcz.us-west-2.rds.amazonaws.com/llm\",\n",
    "    #\"jdbc:awsathena://athena.us-west-2.amazonaws.com:443/tpcds_bin_partitioned_orc_300?s3_staging_dir=s3://tangqy-athenaoutput/&aws_credentials_provider_class=com.amazonaws.auth.DefaultAWSCredentialsProviderChain\",\n",
    "    include_tables=['dws_truck_portrait_index_sum_da','dws_ots_waybill_info_da','ads_bi_quality_monitor_shipping_detail','dim_pub_truck_info'], # we include only one table to save tokens in the prompt :)\n",
    "    #include_tables=[\"customer\"],\n",
    "    sample_rows_in_table_info=0)\n",
    "#chain = create_sql_query_chain(sm_llm, db)\n",
    "#response = chain.invoke({\"question\":\"最近一个月温度合格的派车单数量\"})\n",
    "#response = chain.invoke({\"question\":\"最近一个月下单最大的客户邮件地址\"})\n",
    "\n",
    "#print(response)\n",
    "#db_chain = CustomerizedSQLDatabaseChain(llm=llm, database=db, verbose=True, top_k=3)\n",
    "#db_chain.run(\"最近一个月温度合格的派车单数量\")\n",
    "#db_chain.run(\"I need to know the max sales customer's id in sales report\")\n",
    "### for bedrock#######\n",
    "db_chain = CustomerizedSQLDatabaseChain.from_llm(llm=bedrock_llm, db=db, verbose=False, return_sql=True)\n",
    "#db_chain.run(\"2023年7月派车单数量超过26次的4.2米车辆一共有多少辆?\")\n",
    "#db_chain.run(\"历史累计派车单数量、干线派车单数量、城配派车单数量\")\n",
    "#db_chain.run(\"2022年的运输总量是多少吨?\")\n",
    "db_chain.run(\"成都市的车辆资源累计有多少？\")\n",
    "#db_chain.run(\"I need to know the max sales customer's id in sales report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bb8873-80a1-411e-9613-8dadccdbec0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
